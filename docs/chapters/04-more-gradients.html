<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Higher Dimensions ‚Äì Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/06-regularization.html" rel="next">
<link href="../chapters/03-maximum-likelihood.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-a14e345711173c227b21482e2eb4cc70.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d8b0bb70be28f5ebcc1c8c98afdc075d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
div.callout-question.callout {
  border-left-color: lightblue;
}
div.callout-question.callout-style-default > .callout-header {
  background-color: rgb(from lightblue r g b / 13%);
}
div.callout-question .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-question.callout-style-default .callout-icon::before, div.callout-question.callout-titled .callout-icon::before {
  content: '‚ùì';
  background-image: none;
}
div.callout-sol.callout {
  border-left-color: pink;
}
div.callout-sol.callout-style-default > .callout-header {
  background-color: rgb(from pink r g b / 13%);
}
div.callout-sol .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-sol.callout-style-default .callout-icon::before, div.callout-sol.callout-titled .callout-icon::before {
  content: 'üìù';
  background-image: none;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/02-signal-noise.html">Machine Learning Fundamentals</a></li><li class="breadcrumb-item"><a href="../chapters/04-more-gradients.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Higher Dimensions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning Fundamentals</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-signal-noise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Data = Signal + Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-maximum-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimation and Gradients</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-more-gradients.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Higher Dimensions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Features and Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-bias-variance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">More on Overfitting</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-intro-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction: Binary Labels</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-assessment-of-classifiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assessment of Classifiers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12-decision-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Decision Theory in Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/15-multinomial-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multinomial Classification</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#recap" id="toc-recap" class="nav-link active" data-scroll-target="#recap">Recap</a></li>
  <li><a href="#multivariate-linear-gaussian-model" id="toc-multivariate-linear-gaussian-model" class="nav-link" data-scroll-target="#multivariate-linear-gaussian-model">Multivariate Linear-Gaussian Model</a>
  <ul class="collapse">
  <li><a href="#log-likelihood-and-mean-squared-error" id="toc-log-likelihood-and-mean-squared-error" class="nav-link" data-scroll-target="#log-likelihood-and-mean-squared-error">Log-Likelihood and Mean-Squared Error</a></li>
  <li><a href="#matrices-and-norms" id="toc-matrices-and-norms" class="nav-link" data-scroll-target="#matrices-and-norms">Matrices and Norms</a></li>
  </ul></li>
  <li><a href="#deriving-and-checking-gradient-formulas" id="toc-deriving-and-checking-gradient-formulas" class="nav-link" data-scroll-target="#deriving-and-checking-gradient-formulas">Deriving and Checking Gradient Formulas</a>
  <ul class="collapse">
  <li><a href="#entrywise-derivation" id="toc-entrywise-derivation" class="nav-link" data-scroll-target="#entrywise-derivation">Entrywise Derivation</a></li>
  <li><a href="#vector-derivation" id="toc-vector-derivation" class="nav-link" data-scroll-target="#vector-derivation">Vector Derivation</a></li>
  <li><a href="#checking-vector-identities" id="toc-checking-vector-identities" class="nav-link" data-scroll-target="#checking-vector-identities">Checking Vector Identities</a></li>
  </ul></li>
  <li><a href="#implementing-multivariate-regression" id="toc-implementing-multivariate-regression" class="nav-link" data-scroll-target="#implementing-multivariate-regression">Implementing Multivariate Regression</a>
  <ul class="collapse">
  <li><a href="#object-oriented-api-for-machine-learning-models" id="toc-object-oriented-api-for-machine-learning-models" class="nav-link" data-scroll-target="#object-oriented-api-for-machine-learning-models">Object-Oriented API for Machine Learning Models</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/02-signal-noise.html">Machine Learning Fundamentals</a></li><li class="breadcrumb-item"><a href="../chapters/04-more-gradients.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Higher Dimensions</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Higher Dimensions</span></h1>
<p class="subtitle lead">Working with models and gradients with many features</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em><a href="https://colab.research.google.com/github/philchodrow/ml-notes-update/blob/main/docs/live-notebooks/04-more-gradients.ipynb">Open the live notebook</a> in Google Colab.</em></p>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">Recap</h2>
<p><a href="../chapters/03-maximum-likelihood.html">Last time</a>, we developed an end-to-end example of maximum-likelihood estimation for the 1-dimensional linear-Gaussian model, which allowed us to fit a regression line to data displaying a linear trend. We saw that we could use the gradient of the log-likelihood function (or in this case, equivalently, the mean-squared error) to iteratively update a guess for the optimal parameters using gradient descent.</p>
<p>The model we learned to fit had two parameters, <span class="math inline">\(w_1\)</span> and <span class="math inline">\(w_0\)</span>. However, modern models have vastly more parameters, with frontier LLMs having parameter counts nearing the trillions. In order to reason about these models, we need to build fluency in reasoning about high-dimensional spaces of parameters. We turn to this now, with a focus on multivariate linear regression.</p>
</section>
<section id="multivariate-linear-gaussian-model" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="multivariate-linear-gaussian-model">Multivariate Linear-Gaussian Model</h2>
<p>Recall that the 1-dimensional linear-Gaussian model assumed that the target variable <span class="math inline">\(y\)</span> was generated from a linear function of a single feature <span class="math inline">\(x\)</span> plus Gaussian noise. We can write this as:</p>
<p><span class="math display">\[
\begin{aligned}
    y_i \sim \mathcal{N}(w_1 x_i + w_0, \sigma^2)
\end{aligned}
\]</span></p>
<p>Suppose now that we have more than one predictive feature, which we would like to use in our model. Given <span class="math inline">\(p\)</span> features <span class="math inline">\(x_1,\ldots,x_p\)</span>, we can extend the linear-Gaussian model to incorpoate all of them:</p>
<p><span id="eq-multivar-linear-gaussian-verbose"><span class="math display">\[
\begin{aligned}
    y_i \sim \mathcal{N}(w_1 x_{i1} + w_2 x_{i2} + \cdots + w_p x_{ip} + w_0, \sigma^2) = \mathcal{N}\left(\sum_{j=1}^p w_j x_{ij} + w_0, \sigma^2\right)
\end{aligned}
\tag{3.1}\]</span></span></p>
<p>Here‚Äôs a visualization of a regression model with two features, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, alongside the plane defined by the linear function of these features.</p>
<div id="d5d5a961" class="cell page-columns page-full" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">0</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(n_samples, <span class="dv">2</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>true_w <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>true_b <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> X <span class="op">@</span> true_w <span class="op">+</span> true_b <span class="op">+</span> <span class="dv">1</span> <span class="op">*</span> torch.randn(n_samples)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>ax.scatter(X[:, <span class="dv">0</span>].numpy(), X[:, <span class="dv">1</span>].numpy(), y.numpy(), c<span class="op">=</span><span class="st">'b'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r'Feature </span><span class="dv">$</span><span class="vs">x_1</span><span class="dv">$</span><span class="vs">'</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="vs">r'Feature </span><span class="dv">$</span><span class="vs">x_2</span><span class="dv">$</span><span class="vs">'</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'Target y'</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'3D Scatter Plot of Synthetic Data'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the regression plane</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>xx1, xx2 <span class="op">=</span> torch.meshgrid(torch.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">10</span>), torch.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">10</span>), indexing<span class="op">=</span><span class="st">'ij'</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> true_w[<span class="dv">0</span>] <span class="op">*</span> xx1 <span class="op">+</span> true_w[<span class="dv">1</span>] <span class="op">*</span> xx2 <span class="op">+</span> true_b</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(xx1.numpy(), xx2.numpy(), zz.numpy(), alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the residuals</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    ax.plot([X[i, <span class="dv">0</span>].item(), X[i, <span class="dv">0</span>].item()], </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>            [X[i, <span class="dv">1</span>].item(), X[i, <span class="dv">1</span>].item()], </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            [y[i].item(), (true_w <span class="op">@</span> X[i] <span class="op">+</span> true_b).item()], </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>

<div class="no-row-height column-margin column-container"><div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="04-more-gradients_files/figure-html/cell-4-output-1.png" class="figure-img" width="265" height="272"></p>
<figcaption>3D Scatter Plot of Synthetic Data with Regression Plane and Residuals</figcaption>
</figure>
</div>
</div></div></div>
<p>In order to write down <a href="#eq-multivar-linear-gaussian-verbose" class="quarto-xref">Equation&nbsp;<span>3.1</span></a> more compactly, we need to introduce some notation. We‚Äôll collect the features for data point <span class="math inline">\(i\)</span> into a vector:</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{x}_i = (x_{i0}, x_{i1},x_{i2},\ldots,x_{ip})
\end{aligned}
\]</span></p>
<p>where we assume that <span class="math inline">\(x_{i0} = 1\)</span> is a constant feature included to capture the intercept term <span class="math inline">\(w_0\)</span>. We also collect the parameters into a vector:</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{w}= (w_0, w_1, w_2, \ldots, w_p)
\end{aligned}
\]</span></p>
<div class="page-columns page-full"><p>With this notation, we can rewrite the sum appearing in the mean of the Gaussian in <a href="#eq-multivar-linear-gaussian-verbose" class="quarto-xref">Equation&nbsp;<span>3.1</span></a> as an inner product between the feature vector <span class="math inline">\(\mathbf{x}_i\)</span> and the parameter vector <span class="math inline">\(\mathbf{w}\)</span>: </p><div class="no-row-height column-margin column-container"><span class="margin-aside">An inner product is also often called a dot product. <a href="#eq-inner-product" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> can equivalently be written with the notation <span class="math inline">\( \mathbf{x}_i^T \mathbf{w} = \mathbf{x}_i \cdot \mathbf{w}= \langle \mathbf{x}_i,\mathbf{w} \rangle\)</span>.</span></div></div>
<p><span id="eq-inner-product"><span class="math display">\[
\begin{aligned}
     \mathbf{x}_i^T \mathbf{w} =  \sum_{j=0}^p w_j x_{ij} = 1\cdot w_0 + \sum_{j=1}^p w_j x_{ij} = 1\cdot w_0 + \sum_{j=1}^p w_j x_{ij}\;.
\end{aligned}
\tag{3.2}\]</span></span></p>
<p>The choice of <span class="math inline">\(x_{i0} = 1\)</span> ensures that the intercept term <span class="math inline">\(w_0\)</span> is included in the inner product. This is so convenient that we‚Äôll assume it from now on.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Assumption
</div>
</div>
<div class="callout-body-container callout-body">
<p>From this point forwards, we assume that the feature vector <span class="math inline">\(\mathbf{x}_i\)</span> begins with a constant feature <span class="math inline">\(x_{i0} = 1\)</span>.</p>
</div>
</div>
<p>This notation allows us to compactly rewrite the multivariate linear-Gaussian model as:</p>
<p><span class="math display">\[
\begin{aligned}
    y_i \sim \mathcal{N}( \mathbf{x}_i^T \mathbf{w}, \sigma^2)
\end{aligned}
\]</span></p>
<p>regardless of the number of features. We can make things even a bit simpler by defining a <em>score</em> <span class="math inline">\(s_i\)</span> associated to each data point <span class="math inline">\(i\)</span>:</p>
<p><span id="eq-linear-score"><span class="math display">\[
\begin{aligned}
    s_i =  \mathbf{x}_i^T \mathbf{w}
\end{aligned}
\tag{3.3}\]</span></span></p>
<p>after which we can write: <span class="math display">\[
\begin{aligned}
    y_i \sim \mathcal{N}(s_i, \sigma^2)
\end{aligned}
\]</span></p>
<section id="log-likelihood-and-mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="log-likelihood-and-mean-squared-error">Log-Likelihood and Mean-Squared Error</h3>
<p>The log-likelihood function of the multivariate linear-Gaussian model is given by</p>
<p><span class="math display">\[
\begin{aligned}
    \mathcal{L}(\mathbf{w}) &amp;= \sum_{i=1}^n \log p_Y(y_i ; s_i, \sigma^2) \\
    &amp;= \sum_{i=1}^n \log \left( \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{(y_i - s_i)^2}{2 \sigma^2}\right) \right) \\
    &amp;= -\frac{n}{2} \log(2 \pi \sigma^2) - \frac{1}{2 \sigma^2} \sum_{i=1}^n (y_i - s_i)^2\;,
\end{aligned}
\]</span></p>
<p>which, like last time, means that our maximum-likelihood estimation problem is equivalent to minimizing the mean-squared error between the observed targets <span class="math inline">\(y_i\)</span> and the scores <span class="math inline">\(s_i\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    R(\mathbf{x}, \mathbf{y}; \mathbf{w}) = \frac{1}{n} \sum_{i=1}^n (y_i - s_i)^2 = \frac{1}{n} \sum_{i=1}^n (y_i -  \mathbf{x}_i^T \mathbf{w})^2\;.
\end{aligned}
\]</span></p>
<p>In theory, we‚Äôre ready to start taking gradients and minimizing this function. However, it‚Äôs helpful to try to first simplify our notation <em>even more</em>, which we can do with the introduction of matrix and norm notation.</p>
</section>
<section id="matrices-and-norms" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="matrices-and-norms">Matrices and Norms</h3>
<div class="page-columns page-full"><p>Recall that the <em>Euclidean norm</em> of a vector <span class="math inline">\(\mathbf{v}\in \mathbb{R}^d\)</span> is defined by the formula </p><div class="no-row-height column-margin column-container"><span class="margin-aside">More generally, the <span class="math inline">\(\ell_p\)</span>-norm of vector <span class="math inline">\(\mathbf{v}\)</span> is defined by the equation <span class="math display">\[
\begin{aligned}
    \lVert \mathbf{v} \rVert_p = \sqrt[p]{\sum_{j = 1}^d v_j^p}\;.
\end{aligned}
\]</span> For simplicity, whenever we write <span class="math inline">\(\lVert \mathbf{v} \rVert\)</span> without a subscript, we mean the <span class="math inline">\(\ell_2\)</span>-norm, i.e.&nbsp;<span class="math inline">\(\lVert \mathbf{v} \rVert = \lVert \mathbf{v} \rVert_2\)</span>.</span></div></div>
<p><span class="math display">\[
\begin{aligned}
    \lVert \mathbf{v} \rVert^2 = \sum_{j=1}^d v_j^2\;.
\end{aligned}
\]</span></p>
<p>The norm notation allows us to eliminate the explicit summation in favor of vector operations:</p>
<p><span class="math display">\[
\begin{aligned}
    R(\mathbf{x}, \mathbf{y}; \mathbf{w}) = \frac{1}{n} \lVert \mathbf{y}- \mathbf{s} \rVert^2\;,
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{s}\)</span> is the vector of scores for all data points, whose <span class="math inline">\(i\)</span>th entry is given by <a href="#eq-linear-score" class="quarto-xref">Equation&nbsp;<span>3.3</span></a>. Our last step is to give a compact formula for <span class="math inline">\(\mathbf{s}\)</span>. To do this, we collect all of the feature vectors <span class="math inline">\(\mathbf{x}_i\)</span> into a matrix <span class="math inline">\(\mathbf{X}\in \mathbb{R}^{n \times (p+1)}\)</span>, whose <span class="math inline">\(i\)</span>th row is given by <span class="math inline">\(\mathbf{x}_i^T\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{X}= \left[\begin{matrix}
    - &amp; \mathbf{x}_1^T &amp; - \\
    - &amp; \mathbf{x}_2^T &amp; - \\
    &amp; \vdots &amp; \\
    - &amp; \mathbf{x}_n^T &amp; -
    \end{matrix}\right]\;.
\end{aligned}
\]</span></p>
<p>Now, if we multiply the matrix <span class="math inline">\(\mathbf{X}\)</span> by the parameter vector <span class="math inline">\(\mathbf{w}\)</span>, we obtain</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{X}\mathbf{w}= \left[\begin{matrix}
    - &amp; \mathbf{x}_1^T &amp; - \\
    - &amp; \mathbf{x}_2^T &amp; - \\
    &amp; \vdots &amp; \\
    - &amp; \mathbf{x}_n^T &amp; -
    \end{matrix}\right] \mathbf{w}= \left[\begin{matrix}
     \mathbf{x}_1^T \mathbf{w} \\
     \mathbf{x}_2^T \mathbf{w} \\
    \vdots \\
     \mathbf{x}_n^T \mathbf{w}
    \end{matrix}\right] =
    \left[\begin{matrix}
    s_1 \\
    s_2 \\
    \vdots \\
    s_n
    \end{matrix}\right] =
    \mathbf{s}\;,
\end{aligned}
\]</span></p>
<p>This gives us our compact formula for the MSE:</p>
<p><span id="eq-mse-matrix-form"><span class="math display">\[
\begin{aligned}
    R(\mathbf{x}, \mathbf{y}; \mathbf{w}) = \frac{1}{n}\lVert \mathbf{X}\mathbf{w}- \mathbf{y} \rVert^2\;.
\end{aligned}
\tag{3.4}\]</span></span></p>
<div class="page-columns page-full"><p>The maximum-likelihood problem for the multivariate linear-Gaussian model can therefore be written </p><div class="no-row-height column-margin column-container"><span class="margin-aside">Since the <span class="math inline">\(\frac{1}{n}\)</span> is a positive constant, it does not affect the location of the minimum and can be ignored in the optimization problem.</span></div></div>
<p><span id="eq-mse-optimization"><span class="math display">\[
\begin{aligned}
    \hat{\mathbf{w}} = \mathop{\mathrm{arg\,min}}_\mathbf{w}\lVert \mathbf{X}\mathbf{w}- \mathbf{y} \rVert^2\;.
\end{aligned}
\tag{3.5}\]</span></span></p>
</section>
</section>
<section id="deriving-and-checking-gradient-formulas" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="deriving-and-checking-gradient-formulas">Deriving and Checking Gradient Formulas</h2>
<p>To solve the optimization problem in <a href="#eq-mse-optimization" class="quarto-xref">Equation&nbsp;<span>3.5</span></a>, we will need the gradient of <span class="math inline">\(R\)</span> with respect to <span class="math inline">\(\mathbf{w}\)</span>. To do so, we‚Äôll highlight two approaches.</p>
<section id="entrywise-derivation" class="level3">
<h3 class="anchored" data-anchor-id="entrywise-derivation">Entrywise Derivation</h3>
<p>To compute the gradient of <span class="math inline">\(R\)</span> entrywise, we start by explicitly rewriting <span class="math inline">\(R\)</span> in summation notation, avoiding matrix and vector notation for the moment:</p>
<p><span class="math display">\[
\begin{aligned}
    R(\mathbf{x}, \mathbf{y}; \mathbf{w}) = \frac{1}{n} \sum_{i=1}^n (y_i -  \mathbf{x}_i^T \mathbf{w})^2 = \frac{1}{n} \sum_{i=1}^n (y_i - \sum_{j=0}^p w_j x_{ij})^2\;.
\end{aligned}
\]</span></p>
<p>We now take the derivative with respect to a particular parameter <span class="math inline">\(w_k\)</span>:</p>
<p><span id="eq-mse-gradient-entrywise"><span class="math display">\[
\begin{aligned}
    \frac{\partial R}{\partial w_k} &amp;= \frac{\partial}{\partial w_k} \left( \frac{1}{n} \sum_{i=1}^n (y_i - \sum_{j=0}^p w_j x_{ij})^2 \right) \\
    &amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial}{\partial w_k} \left(y_i - \sum_{j=0}^p w_j x_{ij}\right)^2 \\
    &amp;= \frac{1}{n} \sum_{i=1}^n 2 \left(y_i - \sum_{j=0}^p w_j x_{ij}\right) \cdot \left(-x_{ik}\right) &amp;\quad \text{(chain rule)}\\
    &amp;= -\frac{2}{n} \sum_{i=1}^n x_{ik} \left(y_i -  \mathbf{x}_i^T \mathbf{w}\right) \\
    &amp;= \frac{2}{n} \sum_{i=1}^n x_{ik} \left( \mathbf{x}_i^T \mathbf{w} - y_i\right)\;.
\end{aligned}
\tag{3.6}\]</span></span></p>
</section>
<section id="vector-derivation" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="vector-derivation">Vector Derivation</h3>
<div class="page-columns page-full"><p>It‚Äôs more convenient and insightful to compute the gradient in vector form. This requires a few <em>gradient identities</em>, each of which can be derived and verified using entrywise methods like the one above. For our case, we need two identities </p><div class="no-row-height column-margin column-container"><span class="margin-aside">In both these identities, the gradient is taken with respect to <span class="math inline">\(\mathbf{v}\)</span>.</span></div></div>
<div id="prp-norm-grad" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.1 (Gradient of Norm Squared)</strong></span> For any <span class="math inline">\(\mathbf{v}_0 \in \mathbb{R}^d\)</span>, if <span class="math inline">\(f(\mathbf{v}) = \lVert \mathbf{v} \rVert^2\)</span>, then <span class="math display">\[
\nabla f(\mathbf{v}_0) = 2 \mathbf{v}_0\;.
\]</span></p>
</div>
<div id="prp-linear-map-grad" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.2 (Compositions with Linear Maps)</strong></span> Let <span class="math inline">\(f: \mathbb{R}^m \to \mathbb{R}\)</span> be a differentiable function, and let <span class="math inline">\(\mathbf{A}\in \mathbb{R}^{m \times n}\)</span> be a matrix. Define <span class="math inline">\(g: \mathbb{R}^n \to \mathbb{R}\)</span> by <span class="math inline">\(g(\mathbf{v}) = f(\mathbf{A}\mathbf{v})\)</span>. Then, for any <span class="math inline">\(\mathbf{v}_0 \in \mathbb{R}^n\)</span>,</p>
<p><span class="math display">\[
\nabla g(\mathbf{v}_0) = \mathbf{A}^T \nabla f(\mathbf{A}\mathbf{v}_0)\;.
\]</span></p>
</div>
<p>If we apply these identities to <a href="#eq-mse-matrix-form" class="quarto-xref">Equation&nbsp;<span>3.4</span></a>, we obtain</p>
<p><span class="math display">\[
\begin{aligned}
    \nabla R(\mathbf{x}, \mathbf{y}; \mathbf{w}) = \nabla \left( \frac{1}{n} \lVert \mathbf{X}\mathbf{w}- \mathbf{y} \rVert^2 \right) &amp;= \frac{1}{n} \nabla \lVert \mathbf{X}\mathbf{w}- \mathbf{y} \rVert^2 \\
    &amp;= \frac{1}{n}\mathbf{X}^T \nabla \lVert \mathbf{X}\mathbf{w}- \mathbf{y} \rVert^2 &amp;\quad \text{(Prop 3.2)}\\
    &amp;= \frac{1}{n}\mathbf{X}^T \cdot 2(\mathbf{X}\mathbf{w}- \mathbf{y}) &amp;\quad \text{(Prop 3.1)}\\
    &amp;= \frac{2}{n} \mathbf{X}^T (\mathbf{X}\mathbf{w}- \mathbf{y})\;.
\end{aligned}
\]</span></p>
<p>It‚Äôs possible to check that this vector formula for the gradient matches the entrywise formula from <a href="#eq-mse-gradient-entrywise" class="quarto-xref">Equation&nbsp;<span>3.6</span></a> by verifying that the <span class="math inline">\(k\)</span>th entry of the vector formula equals the entrywise formula for arbitrary <span class="math inline">\(k\)</span>.</p>
</section>
<section id="checking-vector-identities" class="level3">
<h3 class="anchored" data-anchor-id="checking-vector-identities">Checking Vector Identities</h3>
<p>How do we know that vector gradient identities like the ones we used above are correct? The most direct way is to verify them <em>entrywise</em>. To verify a vector identity entrywise, we just check that the <span class="math inline">\(k\)</span>th entry of the left-hand side equals the <span class="math inline">\(k\)</span>th entry of the right-hand side, for an arbitrary index <span class="math inline">\(k\)</span>. For example, let‚Äôs verify the first identity above, <span class="math inline">\(\nabla \lVert \mathbf{v} \rVert^2 = 2\mathbf{v}\)</span>. The <span class="math inline">\(k\)</span>th entry of the left-hand side is given by the partial derivative with respect to entry <span class="math inline">\(w_k\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    \left(\nabla \lVert \mathbf{v} \rVert^2\right)_k = \frac{\partial}{\partial v_k} \lVert \mathbf{v} \rVert^2 = \frac{\partial}{\partial v_k} \sum_{j=1}^d v_j^2 =  \sum_{j=1}^d \frac{\partial}{\partial v_k} v_j^2 = \sum_{j=1}^d 2\delta_{jk}  v_k = 2 v_k\;,
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\delta_{jk}\)</span> is the Kronecker delta, which equals 1 if <span class="math inline">\(j=k\)</span> and 0 otherwise. The <span class="math inline">\(k\)</span>th entry of the right-hand side is simply <span class="math inline">\(2 v_k\)</span>. Since these are equal for arbitrary <span class="math inline">\(k\)</span>, the identity holds.</p>
</section>
</section>
<section id="implementing-multivariate-regression" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="implementing-multivariate-regression">Implementing Multivariate Regression</h2>
<p>Our implementation for multivariate linear regression is very similar to our implementation for univariate regression from last time, and can actually be more compact in code thanks to our use of matrix operations. <code>torch</code> supplies the syntax <code>X@w</code> for matrix-vector and matrix-matrix multiplication, which we can use to compute the predictions for all data points at once.</p>
<section id="object-oriented-api-for-machine-learning-models" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="object-oriented-api-for-machine-learning-models">Object-Oriented API for Machine Learning Models</h3>
<p>We are going to implement most of our machine learning models using an object-oriented approach which will generalize nicely once we move on to complex deep learning models.</p>
<section id="model-class" class="level4">
<h4 class="anchored" data-anchor-id="model-class">Model Class</h4>
<p>Under <code>torch</code>‚Äôs standard structure, a model is an instance of a <code>class</code> which holds parameters and implements a <code>forward</code> method which computes predictions given input data. Here‚Äôs a minimal implementation for linear regression:</p>
<div id="3a5b9157" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearRegression:</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_params):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> torch.zeros(n_params, <span class="dv">1</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X <span class="op">@</span> <span class="va">self</span>.w</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="loss-function" class="level4">
<h4 class="anchored" data-anchor-id="loss-function">Loss Function</h4>
<p>Alongside the model class, we need a loss function. While there are many possibilities, we‚Äôll use our familiar mean-squared error. The loss function should accept predicted and true target values, and return a scalar loss value.</p>
<div id="a7eab2d5" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse(y_pred, y):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.mean((y_pred <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="optimizer" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="optimizer">Optimizer</h4>
<p>The last thing we need is an <em>algorithm</em> for optimizing the parameters of the model. Gradient descent is one such algorithm. Here, we‚Äôll implement a simple version of gradient descent as a separate class:</p>
<div id="986677d3" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GradientDescentOptimizer:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, lr<span class="op">=</span><span class="fl">1e-2</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># once we begin to rely on automatic differentiation</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we won't need to implement this ourselves</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> grad_func(<span class="va">self</span>, X, y): </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> <span class="va">self</span>.model.forward(X)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> (<span class="dv">2</span><span class="op">/</span>n) <span class="op">*</span> X.T <span class="op">@</span> (y_pred <span class="op">-</span> y)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> gradient</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, X, y):</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> <span class="va">self</span>.model.forward(X)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> <span class="va">self</span>.grad_func(X, y)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we‚Äôre ready to run multivariate linear regression. Let‚Äôs generate some random synthetic data for testing.</p>
<div id="ee1e0d53" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(n_samples, n_features)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.cat([torch.ones(n_samples, <span class="dv">1</span>), X], dim<span class="op">=</span><span class="dv">1</span>) <span class="co"># shape (n_samples, n_features + 1)</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>true_w <span class="op">=</span> torch.randn(n_features <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>signal <span class="op">=</span> X <span class="op">@</span> true_w</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> torch.randn(n_samples, <span class="dv">1</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> signal <span class="op">+</span> noise</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>With this data, we can check that our vector gradient formula matches the entrywise formula we derived earlier, which we can do via torch‚Äôs automatic differentiation:</p>
<div id="d4dc63ac" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-6"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-6-1"><a href="#annotated-cell-6-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression(n_params<span class="op">=</span>n_features <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="annotated-cell-6-2"><a href="#annotated-cell-6-2" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> GradientDescentOptimizer(model<span class="op">=</span>model, lr<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="annotated-cell-6-3"><a href="#annotated-cell-6-3" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-6-4" class="code-annotation-target"><a href="#annotated-cell-6-4" aria-hidden="true" tabindex="-1"></a>grad_manual <span class="op">=</span> opt.grad_func(X, y)</span>
<span id="annotated-cell-6-5"><a href="#annotated-cell-6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-6-6"><a href="#annotated-cell-6-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.forward(X)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-6-7" class="code-annotation-target"><a href="#annotated-cell-6-7" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> mse(y_pred, y)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-6-8" class="code-annotation-target"><a href="#annotated-cell-6-8" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="annotated-cell-6-9"><a href="#annotated-cell-6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-6-10"><a href="#annotated-cell-6-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.allclose(grad_manual, model.w.grad))  <span class="co"># Should print True</span></span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-6" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="4" data-code-annotation="1">Compute the gradient manually using the optimizer‚Äôs function.</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="7" data-code-annotation="2">Compute the loss using the <code>mse</code> function.</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="8" data-code-annotation="3">Use PyTorch‚Äôs automatic differentiation to compute the gradient.</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="page-columns page-full"><p>Looks fine! Now that we have gradient descent implemented, we can consider the gradient descent algorithm itself. This time, we‚Äôll implement gradient descent as two functions: one which performs a single step of gradient descent, and one which handles the main loop, including storing values of the loss and checking for convergence. </p><div class="no-row-height column-margin column-container"><span class="margin-aside">There are many ways to check for convergence. Here, we‚Äôre just testing whether <span class="math inline">\(\lVert \mathbf{w}_\mathrm{new} - \mathbf{w}_\mathrm{old} \rVert\)</span> is small, which is one way to quantifying the idea that <span class="math inline">\(\mathbf{w}\)</span> ‚Äúhasn‚Äôt changed much‚Äù in a single iteration.</span></div></div>
<div id="8c0c639c" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># training loop</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>loss_history <span class="op">=</span> []</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.forward(X)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> mse(y_pred, y)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    loss_history.append(loss.item())</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    opt.step(X, y)  <span class="co"># perform a single gradient descent step</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convergence check</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(loss_history) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">abs</span>(loss_history[<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> loss_history[<span class="op">-</span><span class="dv">2</span>]) <span class="op">&lt;</span> <span class="fl">1e-6</span>:</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Converged"</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Converged</code></pre>
</div>
</div>
<ol type="1">
<li>Initialize a list to store the loss history.</li>
<li>Compute and store the current loss.</li>
<li>Perform a single gradient descent step.</li>
<li>Check for convergence by seeing if the change in parameters is small.</li>
</ol>
<p>Now we‚Äôre ready to run gradient descent.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot loss history</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_history)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iteration'</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Mean Squared Error'</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Gradient Descent Loss History'</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div id="fig-gradient-descent-loss" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-gradient-descent-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="e9729128" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-more-gradients_files/figure-html/cell-11-output-1.png" class="figure-img" width="569" height="442"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-gradient-descent-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: Loss vs.&nbsp;iteration during gradient descent for our manual implementation of multivariate linear regression.
</figcaption>
</figure>
</div>
<p>This time, because we implemented a convergence check, our main loop terminated automatically.</p>
<p>We can compare the learned parameters to the true parameters:</p>
<div id="7ba40b91" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned parameters:</span><span class="ch">\n</span><span class="st">"</span>, model.w.flatten())</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"True parameters:</span><span class="ch">\n</span><span class="st">"</span>, true_w.flatten())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Learned parameters:
 tensor([ 0.8640,  0.3088,  0.2475,  1.0593, -0.9756, -1.2738],
       grad_fn=&lt;ViewBackward0&gt;)
True parameters:
 tensor([ 0.8393,  0.2479,  0.2067,  0.9928, -0.8986, -1.2028])</code></pre>
</div>
</div>
<p>The learned parameters are relatively close to the true parameters we planted in the synthetic data.</p>


</section>
</section>
</section>

<p><br> <br> <span style="color:grey;">¬© Phil Chodrow, 2025</span></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/03-maximum-likelihood.html" class="pagination-link" aria-label="Maximum Likelihood Estimation and Gradients">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimation and Gradients</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/06-regularization.html" class="pagination-link" aria-label="Features and Regularization">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Features and Regularization</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>