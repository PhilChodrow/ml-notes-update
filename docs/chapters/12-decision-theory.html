<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Decision Theory in Classification ‚Äì Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/15-multinomial-classification.html" rel="next">
<link href="../chapters/11-assessment-of-classifiers.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-a14e345711173c227b21482e2eb4cc70.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d8b0bb70be28f5ebcc1c8c98afdc075d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
div.callout-question.callout {
  border-left-color: lightblue;
}
div.callout-question.callout-style-default > .callout-header {
  background-color: rgb(from lightblue r g b / 13%);
}
div.callout-question .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-question.callout-style-default .callout-icon::before, div.callout-question.callout-titled .callout-icon::before {
  content: '‚ùì';
  background-image: none;
}
div.callout-sol.callout {
  border-left-color: pink;
}
div.callout-sol.callout-style-default > .callout-header {
  background-color: rgb(from pink r g b / 13%);
}
div.callout-sol .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-sol.callout-style-default .callout-icon::before, div.callout-sol.callout-titled .callout-icon::before {
  content: 'üìù';
  background-image: none;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-sidebar floating slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/10-intro-classification.html">Classification</a></li><li class="breadcrumb-item"><a href="../chapters/12-decision-theory.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Decision Theory in Classification</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning Fundamentals</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-signal-noise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Data = Signal + Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-maximum-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimation and Gradients</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-more-gradients.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Higher Dimensions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Features and Regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-bias-variance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">More on Overfitting</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-intro-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction: Binary Labels</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-assessment-of-classifiers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assessment of Classifiers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12-decision-theory.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Decision Theory in Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/15-multinomial-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multinomial Classification</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Modern Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/30-autograd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Automatic Differentiation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/31-gradient-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Optimization Techniques: Algorithms and Batching</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#cost-in-decision-making" id="toc-cost-in-decision-making" class="nav-link" data-scroll-target="#cost-in-decision-making">Cost in Decision Making</a></li>
  <li><a href="#model-selection-via-expected-cost" id="toc-model-selection-via-expected-cost" class="nav-link" data-scroll-target="#model-selection-via-expected-cost">Model Selection via Expected Cost</a>
  <ul class="collapse">
  <li><a href="#model-selection-via-expected-cost-1" id="toc-model-selection-via-expected-cost-1" class="nav-link" data-scroll-target="#model-selection-via-expected-cost-1">Model Selection via Expected Cost</a></li>
  </ul></li>
  <li><a href="#i-dont-know-the-reject-option" id="toc-i-dont-know-the-reject-option" class="nav-link" data-scroll-target="#i-dont-know-the-reject-option">‚ÄúI Don‚Äôt Know‚Äù: The Reject Option</a>
  <ul class="collapse">
  <li><a href="#example-in-rain-prediction" id="toc-example-in-rain-prediction" class="nav-link" data-scroll-target="#example-in-rain-prediction">Example in Rain Prediction</a></li>
  <li><a href="#rejection-threshold-selection" id="toc-rejection-threshold-selection" class="nav-link" data-scroll-target="#rejection-threshold-selection">Rejection Threshold Selection</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/10-intro-classification.html">Classification</a></li><li class="breadcrumb-item"><a href="../chapters/12-decision-theory.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Decision Theory in Classification</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Decision Theory in Classification</span></h1>
<p class="subtitle lead">From Predictions to Decisions</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em><a href="https://colab.research.google.com/github/philchodrow/ml-notes-update/blob/main/docs/live-notebooks/12-decision-theory.ipynb">Open the live notebook</a> in Google Colab.</em></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p><a href="../chapters/11-assessment-of-classifiers.html">Last time</a>, we studied a range of metrics for evaluating the performance of a classification model based purely on the correctness or incorrectness of the model‚Äôs predictions. In practice, however, we don‚Äôt typically use predictive models <em>just</em> for predictions ‚Äì we use them to <em>inform decisions</em>.</p>
<ul>
<li>A model which <em>predicts</em> whether or not it will rain tomorrow is used to help me <em>decide</em> whether or not to bring an umbrella.</li>
<li>A model which <em>predicts</em> whether or not a tumor is malignant based on medical imaging is used to help a doctor <em>decide</em> what treatment to recommend.</li>
<li>A model which <em>predicts</em> whether or not a customer will click on an ad is used to help an advertiser <em>decide</em> how much to bid for that ad placement.</li>
</ul>
<p>Let‚Äôs go back for a moment to the confusion matrix of a binary classifier:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>Predicted 0</th>
<th>Predicted 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>True 0</strong></td>
<td>TN</td>
<td>FP</td>
</tr>
<tr class="even">
<td><strong>True 1</strong></td>
<td>FN</td>
<td>TP</td>
</tr>
</tbody>
</table>
<p>An important property of decision-making in the real world is that there are <em>costs</em> and <em>benefits</em> associated with each entry of the confusion matrix. In the example of weather prediction:</p>
<ol type="1">
<li><strong>True Negative (TN)</strong>: The model predicts no rain, and no rain occurs. I do not bring my umbrella, but I remain dry and happy.</li>
<li><strong>False Positive (FP)</strong>: The model predicts rain, but no rain occurs. I bring my umbrella unnecessarily. I am dry and happy, though slightly inconvenienced.</li>
<li><strong>False Negative (FN)</strong>: The model predicts no rain, but it rains. I do not bring my umbrella. I am soaked and unhappy.</li>
<li><strong>True Positive (TP)</strong>: The model predicts rain, and it rains. I bring my umbrella, and I remain dry and happy.</li>
</ol>
<p>Of these four outcomes, the false negative outcome is by far the worst. Thus, if the sole purpose of my model is to help me decide whether or not to bring an umbrella, I should want the model not just to be <em>accurate overall</em>, but more specifically to <em>minimize false negatives</em> (within reason).</p>
<p>More generally:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Context Matters
</div>
</div>
<div class="callout-body-container callout-body">
<p>The best machine learning model for your application is not necessarily the model with the lowest mean-squared error, cross-entropy, or accuracy.</p>
<p><strong>The best model is the model which achieves the best outcomes (on average) as measured by the costs and benefits in your decision-context.</strong></p>
</div>
</div>
</section>
<section id="cost-in-decision-making" class="level2">
<h2 class="anchored" data-anchor-id="cost-in-decision-making">Cost in Decision Making</h2>
<p>Somewhat more generally, I can assign numerical scores to each of the four outcomes in the confusion matrix, each of which represent the <em>Cost</em> associated with that outcome.</p>
<p>Suppose that I evaluated my model on a validation set of 100 examples, finding that the model made 70 true negative predictions, 10 false positives, 5 false negatives, and 15 true positives. I can collect these in the confusion matrix, and then assign costs to each entry of the confusion matrix, as follows:</p>
<div id="tbl-panel" class="quarto-layout-panel anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8.1: Example confusion matrix and cost matrix for a binary prediction problem.
</figcaption>
<div aria-describedby="tbl-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-first" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-first-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Confusion matrix: the number of times each combination of prediction and outcome occurred.
</figcaption>
<div aria-describedby="tbl-first-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Predicted 0</th>
<th style="text-align: left;">Predicted 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>True 0</strong></td>
<td style="text-align: left;">70</td>
<td style="text-align: left;">10</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>True 1</strong></td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">15</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="tbl-panel" style="flex-basis: 50.0%;justify-content: center;">
<div id="tbl-second" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-tbl figure">
<figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-tbl" id="tbl-second-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Cost matrix: the cost associated with each combination of prediction and outcome.
</figcaption>
<div aria-describedby="tbl-second-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Predicted 0</th>
<th style="text-align: left;">Predicted 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>True 0</strong></td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>True 1</strong></td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</div>
</figure>
</div>
<p>The <em>expected cost</em> associated with this model is then the sum of the products of the entries of the confusion matrix and the cost matrix, divided by the total number of examples: <span class="math display">\[
\text{Expected Cost} = \frac{1}{100} (70 \cdot 0 + 10 \cdot 1 + 5 \cdot 10 + 15 \cdot 0) = 0.6
\]</span></p>
<p>Let‚Äôs formalize this idea with some definitions:</p>
<div id="def-cost-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8.1 (Cost Matrix)</strong></span> The <em>cost matrix</em> associated to a binary classification problem is matrix <span class="math inline">\(\mathbf{C}\in \mathbb{R}^{2\times 2}\)</span> whose <span class="math inline">\(ij\)</span>th entry gives the cost associated with predicting outcome <span class="math inline">\(j\)</span> when the true outcome is <span class="math inline">\(i\)</span>. We typically denote the cost matrix as follows:</p>
<p><span class="math display">\[
\mathbf{C}= \begin{bmatrix}
    c_{00} &amp; c_{01} \\
    c_{10} &amp; c_{11}
\end{bmatrix}
\]</span></p>
</div>
<div id="def-confusion-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8.2 (Confusion Matrix, Mathematical Notation)</strong></span> The <em>confusion matrix</em> associated to a binary classification problem is matrix <span class="math inline">\(\mathbf{M}\in \mathbb{R}^{2\times 2}\)</span> whose <span class="math inline">\(ij\)</span>th entry gives the number of examples for which the true outcome is <span class="math inline">\(i\)</span> and the predicted outcome is <span class="math inline">\(j\)</span>. We typically denote the confusion matrix as follows:</p>
<p><span class="math display">\[
\mathbf{M}= \begin{bmatrix}
    m_{00} &amp; m_{01} \\
    m_{10} &amp; m_{11}
\end{bmatrix}
\]</span></p>
</div>
<div id="def-expected-cost" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8.3 (Expected Cost Of a Binary Classifier)</strong></span> Given a cost matrix <span class="math inline">\(\mathbf{C}\in \mathbb{R}^{2\times 2}\)</span>, the expected cost of a binary classifier is the sum over all entries of the confusion matrix of the product of the confusion matrix entry and the corresponding cost matrix entry, divided by the total number of examples:</p>
<p><span class="math display">\[
\begin{aligned}
    \text{Expected Cost} &amp;= \frac{1}{m} \sum_{i=0}^1 \sum_{j=0}^1 m_{ij} c_{ij}\;, \\
    m &amp;= \sum_{i=0}^1 \sum_{j=0}^1 m_{ij}
\end{aligned}
\]</span></p>
<p>The expected cost is a function of the cost matrix <span class="math inline">\(\mathbf{C}\)</span>. Usually we have the ability to modify the confusion matrix <span class="math inline">\(\mathbf{M}\)</span> but not the cost matrix <span class="math inline">\(\mathbf{C}\)</span> (since the costs are determined by the real-world consequences of the model‚Äôs predictions), so we typically think of the expected cost as a function of the confusion matrix and write it <span class="math inline">\(c(\mathbf{M})\)</span>.</p>
</div>
<div class="callout callout-style-simple callout-question no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Question</span>Where does the cost matrix come from?
</div>
</div>
<div class="callout-body-container callout-body">
<p>The cost matrix is an input to the expected cost, but is not typically something that can be learned from the data set on which we‚Äôre making predictions. Rather, the cost matrix usually must be <em>specified</em> by the designers or users of a given machine learning model. This can raise some difficult questions.</p>
<ul>
<li>How much worse is it to get wet from rain than it is to carry an umbrella unnecessarily? Twice as bad? Ten times as bad‚Ä¶?</li>
<li>Autonomous vehicles must make high-frequency decisions about how to respond to unexpected events in their environment. In some cases, this may involve assigning costs associated with injury or death to both the passenger and other drivers, cyclists, or pedestrians. What should the relative costs be, and who decides?</li>
<li>An early automated screen for a rare disease may be used to order expensive follow-up tests. The cost of a false positive is that an unnecessary, costly follow-up test is performed, while the cost of a false negative is that the disease may go undetected and untreated. Constructing a cost matrix here requires matching the ‚Äúunits‚Äù of cost in each of these cases, which may in practice mean that a dollar value must be assigned to human health or human life.</li>
</ul>
</div>
</div>
</section>
<section id="model-selection-via-expected-cost" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="model-selection-via-expected-cost">Model Selection via Expected Cost</h2>
<p>The expected cost gives us a new way to score models, differently from metrics like log-likelihood, accuracy, or AUC. If we have a cost matrix <span class="math inline">\(\mathbf{C}\)</span> that describes the costs associated with our decision context, then we can choose a best model among candidates by choosing the one with the best expected cost, usually as evaluated on validation data.</p>
<div class="callout callout-style-simple callout-question no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Question</span>Why not train the model to minimize expected cost?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Unfortunately it‚Äôs often not practical to train the model directly to minimize the expected cost. One of the primary reasons is that the entries of the confusion matrix (like the number of false positives, for example) are not differentiable functions of the model parameters <span class="math inline">\(\mathbf{w}\)</span>. This means that we can‚Äôt use gradient-based optimization to directly minimize the expected cost.</p>
</div>
</div>
<p>In this experiment, we‚Äôll consider two ways in which we can select among trained models to minimize expected cost.</p>
<p>Let‚Äôs return to the rain prediction problem with logistic regression. We‚Äôll use the same Australian weather data set that <a href="../chapters/10-intro-classification.html">we used</a> when introducing classification. This time we‚Äôre going to take two additional steps in our data preprocessing:</p>
<ol type="1">
<li>We are going to <em>standardize</em> the numerical features.  Standardization entails subtracting off the mean of the feature and dividing by the standard deviation of the feature, so that the resulting standardized feature has mean 0 and standard deviation 1.</li>
<li>We are going to use one-hot encoding to convert the categorical features into multiple binary features.</li>
</ol>
<div class="no-row-height column-margin column-container"><span class="margin-aside">Standardizing the data features helps optimization algorithms converge more quickly; technically, this reduces the <em>condition number of the Hessian matrix of the loss function</em>.</span></div><div id="e1807996" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/middcs/data-science-notes/refs/heads/main/data/australia-weather/weatherAUS.csv"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"y"</span>] <span class="op">=</span> df[<span class="st">"RainTomorrow"</span>].<span class="bu">map</span>({<span class="st">"No"</span>: <span class="dv">0</span>, <span class="st">"Yes"</span>: <span class="dv">1</span>})</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"RainToday"</span>] <span class="op">=</span> df[<span class="st">"RainToday"</span>].<span class="bu">map</span>({<span class="st">"No"</span>: <span class="dv">0</span>, <span class="st">"Yes"</span>: <span class="dv">1</span>})</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>df.drop(columns<span class="op">=</span>[<span class="st">"Date"</span>, <span class="st">"Location"</span>, <span class="st">"RainTomorrow"</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the features of the data frame</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> [<span class="st">"MinTemp"</span>, <span class="st">"MaxTemp"</span>, <span class="st">"Rainfall"</span>, <span class="st">"Evaporation"</span>, <span class="st">"Sunshine"</span>, <span class="st">"WindGustSpeed"</span>, <span class="st">"WindSpeed9am"</span>, <span class="st">"WindSpeed3pm"</span>, <span class="st">"Humidity9am"</span>, <span class="st">"Humidity3pm"</span>, <span class="st">"Pressure9am"</span>, <span class="st">"Pressure3pm"</span>, <span class="st">"Cloud9am"</span>, <span class="st">"Cloud3pm"</span>, <span class="st">"Temp9am"</span>, <span class="st">"Temp3pm"</span>]: </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    df[col] <span class="op">=</span> (df[col] <span class="op">-</span> df[col].mean()) <span class="op">/</span> df[col].std()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># one-hot encode the categorical features</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, columns<span class="op">=</span>[<span class="st">"WindGustDir"</span>, <span class="st">"WindDir9am"</span>, <span class="st">"WindDir3pm"</span>], drop_first<span class="op">=</span><span class="va">True</span>, dtype<span class="op">=</span><span class="bu">int</span>, prefix<span class="op">=</span>[<span class="st">"gustdir"</span>, <span class="st">"wind9"</span>, <span class="st">"wind3"</span>], prefix_sep<span class="op">=</span><span class="st">"_"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># add the constant feature</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"constant"</span>] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We‚Äôll split the data into training, validation, and test sets:</p>
<div id="7b711a2e" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"y"</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df[<span class="st">"y"</span>].values, dtype<span class="op">=</span>torch.float32).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>X_train, X_temp, y_train, y_temp <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.4</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>X_val, X_test, y_val, y_test <span class="op">=</span> train_test_split(X_temp, y_temp, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we‚Äôre ready to implement our model. We‚Äôll use the same binary logistic regression model that we used in <a href="../chapters/10-intro-classification.html">the introduction to classification</a>.</p>
<div id="12b8e140" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x): </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> torch.exp(<span class="op">-</span>x))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> binary_cross_entropy(q, y): </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>torch.mean(y <span class="op">*</span> torch.log(q) <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>y) <span class="op">*</span> torch.log(<span class="dv">1</span><span class="op">-</span>q))</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BinaryLogisticRegression: </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, p_features): </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> torch.zeros(p_features, <span class="dv">1</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X): </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid(X <span class="op">@</span> <span class="va">self</span>.w)    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GradientDescentOptimizer: </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, lr<span class="op">=</span><span class="fl">0.1</span>): </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> grad_func(<span class="va">self</span>, X, y): </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.model.forward(X)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>X.shape[<span class="dv">0</span>] <span class="op">*</span> ((q <span class="op">-</span> y).T <span class="op">@</span> X).T</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, X, y): </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> <span class="va">self</span>.grad_func(X, y)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>This time let‚Äôs wrap the training loop inside a function:</p>
<div id="614619cf" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, X_train, y_train, max_epochs <span class="op">=</span> <span class="dv">1000</span>, tol <span class="op">=</span> <span class="fl">1e-8</span>, lr <span class="op">=</span> <span class="fl">0.01</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    opt <span class="op">=</span> GradientDescentOptimizer(model, lr<span class="op">=</span>lr)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(max_epochs): </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> model.forward(X_train)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> binary_cross_entropy(q, y_train)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.item())</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        opt.step(X_train, y_train)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(losses) <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">and</span> <span class="bu">abs</span>(losses[<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> losses[<span class="op">-</span><span class="dv">2</span>]) <span class="op">&lt;</span> tol: </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losses</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="4a1f11e4" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BinaryLogisticRegression(p_features<span class="op">=</span>X_train.shape[<span class="dv">1</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(model, torch.tensor(X_train.values, dtype<span class="op">=</span>torch.float32), y_train, max_epochs<span class="op">=</span><span class="dv">1000</span>, tol<span class="op">=</span><span class="fl">1e-8</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="model-selection-via-expected-cost-1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="model-selection-via-expected-cost-1">Model Selection via Expected Cost</h3>
<p>With our model in hand, let‚Äôs implement the experiment in which we select a model based on expected cost. We‚Äôll first implement the confusion matrix and expected cost as functions:</p>
<div id="c21efd5f" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> confusion_matrix(y_pred, y_true, threshold<span class="op">=</span><span class="fl">0.5</span>): </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    counts <span class="op">=</span> torch.zeros((<span class="dv">2</span>, <span class="dv">2</span>), dtype<span class="op">=</span>torch.float32)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>): </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>): </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>            counts[i, j] <span class="op">=</span> ((y_pred <span class="op">==</span> j) <span class="op">&amp;</span> (y_true <span class="op">==</span> i)).<span class="bu">sum</span>()</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> counts</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expected_cost(confusion_matrix, cost_matrix): </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> confusion_matrix.<span class="bu">sum</span>().item()</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (confusion_matrix <span class="op">*</span> cost_matrix).<span class="bu">sum</span>().item() <span class="op">/</span> m</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we‚Äôll do our main experiment. In this experiment, we‚Äôll pick two sets of features and train our model on each of these feature sets. We‚Äôll then evaluate the expected cost and accuracy of each model on the validation set across a range of thresholds, and we‚Äôll compare the results. We‚Äôll first define our two sets of features and our cost matrix:</p>
<div id="69fab7e4" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>col_sets <span class="op">=</span> {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Simple"</span> : [<span class="st">"RainToday"</span>, <span class="st">"Humidity3pm"</span>],</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Full"</span> : X_train.columns.drop(<span class="st">"constant"</span>).tolist()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> torch.tensor([[<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">10</span>, <span class="dv">0</span>]], dtype<span class="op">=</span>torch.float32)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>In our main experimental loop, we train a model on the specified set of features and then evaluate the expected cost and accuracy of the model on the validation set across a range of thresholds.</p>
<div id="bc7c871d" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># convenience function for selecting the specified features from a data frame and converting to a tensor</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> select_features(X_df, cols):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"constant"</span> <span class="kw">not</span> <span class="kw">in</span> cols: </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        cols <span class="op">=</span> [<span class="st">"constant"</span>] <span class="op">+</span> cols</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.tensor(X_df[cols].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># train the simple model and obtain predicted probabilities on the validation set</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> select_features(X_train, col_sets[<span class="st">"Simple"</span>])</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>model_simple <span class="op">=</span> BinaryLogisticRegression(p_features<span class="op">=</span>X_train_tensor.shape[<span class="dv">1</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(model_simple, X_train_tensor, y_train, max_epochs<span class="op">=</span><span class="dv">1000</span>, tol<span class="op">=</span><span class="fl">1e-8</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>q_val_simple <span class="op">=</span> model_simple.forward(select_features(X_val, col_sets[<span class="st">"Simple"</span>]))</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> select_features(X_train, col_sets[<span class="st">"Full"</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>model_full <span class="op">=</span> BinaryLogisticRegression(p_features<span class="op">=</span>X_train_tensor.shape[<span class="dv">1</span>])</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(model_full, select_features(X_train, col_sets[<span class="st">"Full"</span>]), y_train, max_epochs<span class="op">=</span><span class="dv">1000</span>, tol<span class="op">=</span><span class="fl">1e-8</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>q_val_full <span class="op">=</span> model_full.forward(select_features(X_val, col_sets[<span class="st">"Full"</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="68fab865" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> costs_and_accuracies(q_val, y_val, C): </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    costs <span class="op">=</span> []</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    accuracies <span class="op">=</span> []</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> torch.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">101</span>): </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> (q_val <span class="op">&gt;=</span> t).<span class="bu">int</span>()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(y_pred, y_val, threshold<span class="op">=</span>t)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> expected_cost(cm, C)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> (cm[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">+</span> cm[<span class="dv">1</span>, <span class="dv">1</span>]) <span class="op">/</span> cm.<span class="bu">sum</span>()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        accuracies.append(acc.item())</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        costs.append(c)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> costs, accuracies</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we‚Äôre ready to run the experiment and plot the results.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">101</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>costs_simple, accuracies_simple <span class="op">=</span> costs_and_accuracies(q_val_simple, y_val, C)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>costs_full, accuracies_full <span class="op">=</span> costs_and_accuracies(q_val_full, y_val, C)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(T, costs_simple, label<span class="op">=</span><span class="st">"Simple model"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(T, costs_full, label<span class="op">=</span><span class="st">"Full model"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].plot(T, accuracies_simple, label<span class="op">=</span><span class="st">"Simple model"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].plot(T, accuracies_full, label<span class="op">=</span><span class="st">"Full model"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].vlines(T[torch.argmin(torch.tensor(costs_full))], <span class="bu">min</span>(costs_full), <span class="bu">max</span>(costs_full), color<span class="op">=</span><span class="st">"black"</span>, linestyle<span class="op">=</span><span class="st">"dashed"</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].vlines(T[torch.argmax(torch.tensor(accuracies_full))], <span class="bu">min</span>(accuracies_full), <span class="bu">max</span>(accuracies_full), color<span class="op">=</span><span class="st">"black"</span>, linestyle<span class="op">=</span><span class="st">"dashed"</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylim(<span class="dv">0</span>, <span class="va">None</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">"Expected Cost (Validation Set)"</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"Cost and Accuracy for Two Models"</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">"Threshold"</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylabel(<span class="st">"Accuracy (Validation Set)"</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div id="fig-model-selection-experiment" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-model-selection-experiment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="0a9b2b5c" class="cell" data-execution_count="13">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="12-decision-theory_files/figure-html/cell-13-output-1.png" class="figure-img" width="470" height="470"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-model-selection-experiment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: Illustration of model selection using accuracy (bottom) and expected cost (top) for a range of thresholds (horizontal axis). The dashed vertical lines indicate the threshold at which the full model achieves its best expected cost and accuracy.
</figcaption>
</figure>
</div>
<p>In this experiment, scoring the model by expected cost and scoring the model by accuracy both lead to use choosing the full model over the simpler one. However, when scoring by accuracy the different might seem negligible:</p>
<div id="05be7603" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Simple model: best accuracy = </span><span class="sc">{</span><span class="bu">max</span>(accuracies_simple)<span class="sc">:.3f}</span><span class="ss"> at t=</span><span class="sc">{</span>T[torch.argmax(torch.tensor(accuracies_simple))]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Full model: best accuracy = </span><span class="sc">{</span><span class="bu">max</span>(accuracies_full)<span class="sc">:.3f}</span><span class="ss"> at t=</span><span class="sc">{</span>T[torch.argmax(torch.tensor(accuracies_full))]<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Simple model: best accuracy = 0.835 at t=0.47
Full model: best accuracy = 0.853 at t=0.50</code></pre>
</div>
</div>
<p>Although there is a noticeable difference in accuracy, it doesn‚Äôt necessarily appear that it should be a big deal. However, the expected cost highlights the difference between the two models much more starkly:</p>
<div id="860c76a4" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Simple model: best expected cost = </span><span class="sc">{</span><span class="bu">min</span>(costs_simple)<span class="sc">:.3f}</span><span class="ss"> at t=</span><span class="sc">{</span>T[torch.argmin(torch.tensor(costs_simple))]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Full model: best expected cost = </span><span class="sc">{</span><span class="bu">min</span>(costs_full)<span class="sc">:.3f}</span><span class="ss"> at t=</span><span class="sc">{</span>T[torch.argmin(torch.tensor(costs_full))]<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Simple model: best expected cost = 0.653 at t=0.08
Full model: best expected cost = 0.457 at t=0.09</code></pre>
</div>
</div>
<p>Here‚Äôs one way to think about what‚Äôs happening here:</p>
<p>When we score the models by <em>accuracy</em>, the models achieve best accuracy in a region of threshold space in which their two accuracies are relatively close.</p>
<p>On the other hand, the cost matrix <span class="math inline">\(\mathbf{C}\)</span> that we used in this experiment assigns a very high cost to false negatives. This means that the expected cost favors models that more frequently predict positives, which corresponds to lowering the threshold. However, in the low-threshold region of the threshold space, the full model is considerably more accurate than the simple model, which in turn means that the full model has a much lower expected cost than the simple model in this region.</p>
</section>
</section>
<section id="i-dont-know-the-reject-option" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="i-dont-know-the-reject-option">‚ÄúI Don‚Äôt Know‚Äù: The Reject Option</h2>
<p>In many application settings, it may be desirable for a model to have an option to ‚Äúreject‚Äù or decline to make a prediction. For example, a model that predicts whether or not a tumor is malignant may be used to help a doctor decide what treatment to recommend. In some cases, the model may be very uncertain about its prediction for a given patient, and it may be desirable for the model to have the option to ‚Äúreject‚Äù making a prediction for that patient, and instead pass the data off to a human expert for further analysis. The process of manual analysis likely to be more expensive than the automated prediction of the model, but is also likely to be more accurate.</p>
<p>Generalizing slightly, we can think of the <strong>reject option</strong> as a third possible outcome for a binary classifier, in which the classifier‚Äôs confidence is sufficiently low that the classifier actually opts to pass the predictive task to a more expensive process (such as a human or a more expensive model).</p>
<p>In the context of binary classification, we would typically implement a reject option by introducing <em>two</em> thresholds <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span>, with <span class="math inline">\(t_1 &lt; t_2\)</span>.</p>
<div id="def-reject-option" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8.4 (The Reject Option in Binary Classification)</strong></span> A binary classifier with a <em>reject option</em> has three possible outcomes based on the predicted score <span class="math inline">\(q(\mathbf{x})\)</span> and two thresholds <span class="math inline">\(t_1 &lt; t_2\)</span>:</p>
<ul>
<li>If <span class="math inline">\(q(\mathbf{x}) &lt; t_1\)</span>, then the classifier predicts 0.</li>
<li>If <span class="math inline">\(q(\mathbf{x}) &gt; t_2\)</span>, then the classifier predicts 1.</li>
<li>If <span class="math inline">\(t_1 \leq q(\mathbf{x}) \leq t_2\)</span>, then the classifier <em>rejects</em> or <em>declines</em> to make a prediction.</li>
</ul>
<p>There is typically a <em>cost</em> associated with the reject option, which is usually less than the cost of a false positive or false negative, but more than the cost of a true positive or true negative.</p>
</div>
<section id="example-in-rain-prediction" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="example-in-rain-prediction">Example in Rain Prediction</h3>
<p>Suppose that we have access to the simple model as part of the free tier of an API. This model is useful, but also less reliable than the full model, which is only available on the paid tier. Each query to the full model costs 0.2 units. So, if we need to make an informed decision each day about the likelihood of rain, we may wish to use the simple model on days when the simple model is relatively certain about the likelihood of rain, and to use the full model on days when the simple model is relatively uncertain about the likelihood of rain.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>counts, bin_edges <span class="op">=</span> torch.histogram(q_val_simple, bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>ax.scatter((bin_edges[:<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> bin_edges[<span class="dv">1</span>:]) <span class="op">/</span> <span class="dv">2</span>, counts, label<span class="op">=</span><span class="st">"Simple model"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"""</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="vs">    More confident </span><span class="kw">(</span><span class="vs">no rain</span><span class="kw">)</span><span class="vs"> &lt;-- Uncertain --&gt; More confident </span><span class="kw">(</span><span class="vs">rain</span><span class="kw">)</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span><span class="dv">$</span><span class="vs">q</span><span class="kw">(</span><span class="dv">\m</span><span class="vs">athbf{x}</span><span class="kw">)</span><span class="dv">$</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="vs">    """</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>ax.fill_between([<span class="fl">0.3</span>, <span class="fl">0.7</span>], <span class="dv">0</span>, <span class="bu">max</span>(counts), color<span class="op">=</span><span class="st">"grey"</span>, alpha<span class="op">=</span><span class="fl">0.1</span>, label<span class="op">=</span><span class="st">"Use simple model"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>ax.annotate(<span class="st">"Example reject region"</span>, xy<span class="op">=</span>(<span class="fl">0.5</span>, <span class="bu">max</span>(counts)<span class="op">/</span><span class="dv">2</span>), xytext<span class="op">=</span>(<span class="fl">0.5</span>, <span class="bu">max</span>(counts)<span class="op">/</span><span class="fl">1.5</span>), ha<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> ax.set_title(<span class="st">"Distribution of Predicted Probabilities on the Validation Set"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div id="fig-example-reject-option" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-example-reject-option-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="99fec3d8" class="cell" data-execution_count="16">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="12-decision-theory_files/figure-html/cell-16-output-1.png" class="figure-img" width="526" height="413"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-example-reject-option-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: Histogram of the predicted probabilities of rain from <code>model_simple</code> on the validation set. The shaded region indicates an example reject region, in which we might want to query <code>model_full</code> instead of <code>model_simple</code>.
</figcaption>
</figure>
</div>
<p>For this reason, we might want to develop a strategy that incorporates <em>both</em> models.</p>
<ul>
<li>First, we query the free, simple model.</li>
<li>If the simple model is relatively certain about the likelihood of rain, then we use the simple model‚Äôs prediction to make our decision.</li>
<li>If the simple model is relatively uncertain about the likelihood of rain, then we query the paid, full model, and we use the full model‚Äôs prediction to make our decision.</li>
</ul>
<p>This will work out well for us <em>if</em> the benefit of using the more expensive full model on the uncertain days outweighs the cost of querying the full model on those days.</p>
<p>As a baseline, let‚Äôs compute the expected cost of using the simple model all the time (with its optimal threshold) and the expected cost of using the full model all the time (with its optimal threshold), including the cost of querying the full model in the latter case.</p>
<div id="254fda7e" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>reject_cost <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="bu">min</span>(costs_simple)<span class="sc">:.3f}</span><span class="ss"> = expected cost of using simple model all the time"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="bu">min</span>(costs_full) <span class="op">+</span> reject_cost<span class="sc">:.3f}</span><span class="ss"> = expected cost of using full model all the time (including cost of querying full model)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.653 = expected cost of using simple model all the time
0.657 = expected cost of using full model all the time (including cost of querying full model)</code></pre>
</div>
</div>
<p>So, using the simple model all the time is better than using the full model all the time, but maybe we can do better by using the simple model when it‚Äôs relatively certain and using the full model when the simple model is relatively uncertain. Let‚Äôs find out by searching over a grid of possible values for <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span>.</p>
</section>
<section id="rejection-threshold-selection" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="rejection-threshold-selection">Rejection Threshold Selection</h3>
<p>As before, we can use the expected cost to help us select the thresholds <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span>, but this time our expected cost becomes more complex. We need to define the two thresholds that we‚Äôll use to define the positive, reject, and negative regions of prediction. We‚Äôll also need to supply the optimal threshold for the full model.</p>
<div id="2143c5c9" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expected_cost_reject_option(q_val, t_1, t_2, t_full, reject_cost <span class="op">=</span> <span class="fl">0.5</span>): </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate the indices for which we are going to reject, and the total cost of those rejections</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    reject_ix <span class="op">=</span> (t_1 <span class="op">&lt;=</span> q_val) <span class="op">&amp;</span> (q_val <span class="op">&lt;=</span> t_2)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    total_reject_cost <span class="op">=</span> reject_ix.<span class="bu">sum</span>().item() <span class="op">*</span> reject_cost </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for the non-rejected examples, we predict 1 if q_val &gt; t_2 and 0 if q_val &lt; t_1. For the rejected examples, we predict according to the full model with threshold t_full.</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> torch.zeros_like(q_val, dtype<span class="op">=</span>torch.int32)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    y_pred[q_val <span class="op">&gt;</span> t_2] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    y_pred[reject_ix] <span class="op">=</span> (q_val_full[reject_ix] <span class="op">&gt;=</span> t_full).<span class="bu">int</span>()</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate the confusion matrix and expected cost for the non-rejected examples</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(y_pred, y_val, threshold<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    total_cost <span class="op">=</span> expected_cost(cm, C) <span class="op">*</span> cm.<span class="bu">sum</span>().item() <span class="op">+</span> total_reject_cost </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    cost_per_example <span class="op">=</span> total_cost <span class="op">/</span> cm.<span class="bu">sum</span>().item()</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost_per_example</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we can run our grid search:</p>
<div id="e54f2958" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>t_1_lim <span class="op">=</span> (<span class="fl">0.0</span>, <span class="dv">1</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>t_2_lim <span class="op">=</span> (<span class="fl">0.0</span>, <span class="dv">1</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>n_grid <span class="op">=</span> <span class="dv">101</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>costs <span class="op">=</span> torch.zeros((n_grid, n_grid))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>best_cost <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>best_t_1 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>best_t_2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t_1 <span class="kw">in</span> <span class="bu">enumerate</span>(torch.linspace(t_1_lim[<span class="dv">0</span>], t_1_lim[<span class="dv">1</span>], n_grid)): </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, t_2 <span class="kw">in</span> <span class="bu">enumerate</span>(torch.linspace(t_2_lim[<span class="dv">0</span>], t_2_lim[<span class="dv">1</span>], n_grid)): </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t_2 <span class="op">&gt;=</span> t_1:</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>            cost <span class="op">=</span> expected_cost_reject_option(q_val_simple, t_1, t_2, t_full<span class="op">=</span>T[torch.argmin(torch.tensor(costs_full))], reject_cost<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            costs[i,j] <span class="op">=</span> cost</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost: </span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>                best_cost, best_t_1, best_t_2 <span class="op">=</span> cost, t_1, t_2</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Let‚Äôs go ahead and visualize the results:</p>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> ax.imshow(costs, origin<span class="op">=</span><span class="st">"lower"</span>, aspect<span class="op">=</span><span class="st">"auto"</span>, zorder <span class="op">=</span> <span class="dv">100</span>, extent <span class="op">=</span> [t_1_lim[<span class="dv">0</span>], t_1_lim[<span class="dv">1</span>], t_2_lim[<span class="dv">0</span>], t_2_lim[<span class="dv">1</span>]], )</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">t_2</span><span class="dv">$</span><span class="vs"> </span><span class="kw">(</span><span class="vs">threshold for predicting 1</span><span class="kw">)</span><span class="vs">"</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">t_1</span><span class="dv">$</span><span class="vs"> </span><span class="kw">(</span><span class="vs">threshold for predicting 0</span><span class="kw">)</span><span class="vs">"</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>ax.scatter(best_t_2, best_t_1, color<span class="op">=</span><span class="st">"red"</span>, label<span class="op">=</span><span class="st">"Best thresholds"</span>, zorder<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im, ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">"Expected Cost"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> ax.set_title(</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="vs">fr"""Expected Cost for Different Thresholds with Reject Option</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="vs">    Optimal cost = </span><span class="sc">{</span>best_cost<span class="sc">:.3f}</span><span class="vs"> at </span><span class="dv">$</span><span class="vs">t_1</span><span class="dv">$</span><span class="vs"> = </span><span class="sc">{</span>best_t_1<span class="sc">:.2f}</span><span class="vs"> and </span><span class="dv">$</span><span class="vs">t_2</span><span class="dv">$</span><span class="vs"> = </span><span class="sc">{</span>best_t_2<span class="sc">:.2f}</span><span class="vs">"""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div id="fig-reject-option-costs" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-reject-option-costs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="26b649a7" class="cell" data-execution_count="20">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="12-decision-theory_files/figure-html/cell-20-output-1.png" class="figure-img" width="496" height="388"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-reject-option-costs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.3: Costs associated with different choices of the thresholds <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span> for the reject option. The red point indicates the optimal thresholds, which achieve an expected cost of {best_cost:.3f}.
</figcaption>
</figure>
</div>
<p>We are able to reduce our expected cost in the rain prediction problem by strategically using the full model on the examples for which the simple model is relatively uncertain. Comparison to <a href="#fig-model-selection-experiment" class="quarto-xref">Figure&nbsp;<span>8.1</span></a> indicates that the optimal reject region corresponds to a threshold zone in which the full model has an especially large advantage in expected cost over the simple model.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">101</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>costs_simple, accuracies_simple <span class="op">=</span> costs_and_accuracies(q_val_simple, y_val, C)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>costs_full, accuracies_full <span class="op">=</span> costs_and_accuracies(q_val_full, y_val, C)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>ax.plot(T, costs_simple, label<span class="op">=</span><span class="st">"Simple model"</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>ax.plot([best_t_1, best_t_2], [<span class="bu">min</span>(costs_full) <span class="op">+</span> <span class="fl">0.2</span>, <span class="bu">min</span>(costs_full) <span class="op">+</span> <span class="fl">0.2</span>], color<span class="op">=</span><span class="st">"black"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, label<span class="op">=</span><span class="st">"Minimum cost of full model + reject cost"</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.plot(T, costs_full, label="Full model")</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>ax.fill_between([best_t_1, best_t_2], <span class="dv">0</span>, <span class="bu">max</span>(costs_full), color<span class="op">=</span><span class="st">"grey"</span>, alpha<span class="op">=</span><span class="fl">0.1</span>, label<span class="op">=</span><span class="st">"Reject region"</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Threshold"</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Expected Cost (Validation Set)"</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Visualizing the Rejection Region"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div id="fig-reject-option-costs-geometric" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-reject-option-costs-geometric-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="c0b72e1d" class="cell" data-execution_count="21">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="12-decision-theory_files/figure-html/cell-21-output-1.png" class="figure-img" width="506" height="368"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-reject-option-costs-geometric-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.4: Visualization of the rejection region in threshold-cost space. The optimal rejection region corresponds to a region of threshold space in which the simple model has a much higher expected cost than the full model, and in which the expected cost of the full model plus the reject cost is lower than the expected cost of the simple model.
</figcaption>
</figure>
</div>
<p>The topic of decision theory is very rich both experimentally and theoretically, and we have only scratched the surface here.</p>


</section>
</section>

<p><br> <br> <span style="color:grey;">¬© Phil Chodrow, 2025</span></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/11-assessment-of-classifiers.html" class="pagination-link" aria-label="Assessment of Classifiers">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assessment of Classifiers</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/15-multinomial-classification.html" class="pagination-link" aria-label="Multinomial Classification">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multinomial Classification</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>