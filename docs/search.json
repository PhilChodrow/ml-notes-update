[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Mathematics [X]\nOpen the live notebook in Google Colab or download the live notebook.\nWe’re going to do some basic tests in this file. Math now seems to work using the include above.\n\\[\n\\begin{aligned}\n    \\mathbb{P}(X) = y\n\\end{aligned}\n\\]\n© Phil Chodrow, 2025",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "index.html#python-interpreter-x",
    "href": "index.html#python-interpreter-x",
    "title": "Machine Learning",
    "section": "Python Interpreter [X]",
    "text": "Python Interpreter [X]\nUse an Anaconda environment\n\nimport torch \nfrom matplotlib import pyplot as plt\n\nprint(torch.__version__)\n\nX = torch.linspace(0, 10, steps=100)\nY = torch.sin(X)\n\nplt.plot(X.numpy(), Y.numpy())\nplt.show()\n\n2.10.0\n\n\n\n\n\n\n\n\n\nDid we see the thing?\nfalse",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "index.html#strip-the-delimiters-for-hidden-code-x",
    "href": "index.html#strip-the-delimiters-for-hidden-code-x",
    "title": "Machine Learning",
    "section": "Strip the delimiters for hidden code [X]",
    "text": "Strip the delimiters for hidden code [X]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "index.html#colab-link-via-an-include-x",
    "href": "index.html#colab-link-via-an-include-x",
    "title": "Machine Learning",
    "section": "Colab link via an include [X]",
    "text": "Colab link via an include [X]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "index.html#strip-solutions-and-hidden-content-e.g.-notes-in-online-website-version.-x",
    "href": "index.html#strip-solutions-and-hidden-content-e.g.-notes-in-online-website-version.-x",
    "title": "Machine Learning",
    "section": "Strip solutions and hidden content (e.g. notes) in online website version. [X]",
    "text": "Strip solutions and hidden content (e.g. notes) in online website version. [X]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "index.html#dont-strip-solutions-and-hidden-content-in-local-notes-version.-x",
    "href": "index.html#dont-strip-solutions-and-hidden-content-in-local-notes-version.-x",
    "title": "Machine Learning",
    "section": "Don’t strip solutions and hidden content in local notes version. [X]",
    "text": "Don’t strip solutions and hidden content in local notes version. [X]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "chapters/01-intro.html",
    "href": "chapters/01-intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "Open the live notebook in Google Colab or download the live notebook.\n\n\n\n  © Phil Chodrow, 2025",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html",
    "href": "chapters/02-signal-noise.html",
    "title": "3  Data = Signal + Noise",
    "section": "",
    "text": "Introduction: Data, Signal, and Noise\nOpen the live notebook in Google Colab or download the live notebook.\nIn these notes, we’ll expand on the following idea:\nConsider the following simple data set:\nWe can think of this data as consisting of two components: a signal expressed by a relationship \\(y \\approx f(x)\\) (in this case \\(f(x) = 2x + 1\\)), and some noise that partially obscures this relationship. Schematically, we can write this relationship as:\n\\[\n\\begin{aligned}\n    y_i = f(x_i) + \\epsilon_i\\;,\n\\end{aligned}\n\\tag{3.1}\\]\nwhich says that the \\(i\\)th value of the target is equal to some function \\(f(x_i)\\) of the input variable \\(x_i\\), plus some random noise term \\(\\epsilon_i\\).\n© Phil Chodrow, 2025",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#introduction-data-signal-and-noise",
    "href": "chapters/02-signal-noise.html#introduction-data-signal-and-noise",
    "title": "3  Data = Signal + Noise",
    "section": "",
    "text": "Machine learning is the science and practice of building algorithms that distinguish between signal and noise in real-world data.\n\n\n\nCode\nimport torch \nfrom matplotlib import pyplot as plt\n\nscatterplot_kwargs = dict(color = \"black\", label = \"data\", facecolors = \"none\", s = 40, alpha = 0.6)\n\nn_points = 20\nx = torch.linspace(0, 10, n_points)\nsignal = 2.0 * x + 1.0  # underlying pattern (signal)\nnoise = torch.randn(n_points) * 3.0  # random noise\n\ny = signal + noise\n\n# Plot residual segments\nfig, ax = plt.subplots(figsize = (6, 4))\nax.scatter(x.numpy(), y.numpy(), **scatterplot_kwargs)\nax.plot(x.numpy(), signal.numpy(), color = \"black\", linestyle = \"--\", label = r\"Signal: $f(x_i) = 2x_i + 1$\")\nfor i in range(n_points):\n    if i == 0: \n        ax.plot([x[i].item(), x[i].item()], [signal[i].item(), y[i].item()], color = \"red\", alpha = 0.3, linewidth = 0.8, label = r\"Noise: $\\epsilon_i$\")\n    else: \n        ax.plot([x[i].item(), x[i].item()], [signal[i].item(), y[i].item()], color = \"red\", alpha = 0.3, linewidth = 0.8)\nax.set(xlabel = r\"$x$\", ylabel = r\"$y$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.1: An illustrative decomposition of a data set (points) into a hypothesized underlying signal (dashed line) and noise (red segments).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#overfitting",
    "href": "chapters/02-signal-noise.html#overfitting",
    "title": "3  Data = Signal + Noise",
    "section": "Overfitting",
    "text": "Overfitting\nIt’s important to emphasize here that the thing we want to learn is not the individual targets \\(y_i\\), but rather the underlying function \\(f(x)\\). To see why, let’s consider an example of what goes wrong if we try to learn the targets \\(y_i\\) exactly. This is called interpolation, and is illustrated by Figure 3.2:\n\nCode\nfrom scipy import interpolate\n# Create an interpolating function\nf_interp = interpolate.interp1d(x.numpy(), y.numpy(), kind='cubic')\nx_dense = torch.linspace(0, 10, 100)\ny_interp = f_interp(x_dense.numpy())\n\nfig, ax = plt.subplots(figsize = (6, 4))\nax.scatter(x.numpy(), y.numpy(), **scatterplot_kwargs)\nax.plot(x_dense.numpy(), y_interp, color = \"red\", linestyle = \"--\", label = \"interpolating fit\", zorder = -10)\nax.set(xlabel = r\"$x$\", ylabel = r\"$y$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.2: A function which exactly interpolates the data, perfectly fitting both signal and noise.\n\n\n\nThe problem with interpolation is that while we have perfectly fit our training data, we have not learned the underlying signal \\(f(x)\\). If we were to generate new data with the same signal but with different noise, we would likely find that our interpolating function doesn’t actually make very good predictions about that data at all: many of its bends and wiggles don’t have any correspondence to features in the new data.\n\nCode\n# Generate new data\ny_new = 2.0 * x_dense + 1.0 + torch.randn(100) * 3.0\nfig, ax = plt.subplots(figsize = (6, 4))\nax.scatter(x_dense.numpy(), y_new.numpy(), **scatterplot_kwargs)\nax.plot(x_dense.numpy(), y_interp, color = \"red\", linestyle = \"--\", label = \"interpolating fit\", zorder = -10)\nax.set(xlabel = r\"$x$\", ylabel = r\"$y$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.3: New data plotted alongside the interpolating fit from the previous figure.\n\n\n\nWe observe a number of irrelevant fluctuations in the interpolating fit that do not correspond to the underlying pattern. This phenomenon is called overfitting: by trying to fit the noise in our training data, we have failed to learn the true signal. We’ll learn how to quantify overfitting once we begin to study measures of model quality.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#modeling-the-noise",
    "href": "chapters/02-signal-noise.html#modeling-the-noise",
    "title": "3  Data = Signal + Noise",
    "section": "Modeling the Noise",
    "text": "Modeling the Noise\nIf we want to learn the signal \\(f\\) in Equation 3.1, it’s helpful to learn how to talk mathematically about the noise term \\(\\epsilon_i\\). To do this, we need to step into the language of probability theory. Our standing assumption will be that the noise terms \\(\\epsilon_i\\) are random variables drawn independently and identically-distributed from some probability distribution. This means that each time we observe a new data point, we get a different value of \\(\\epsilon_i\\) drawn from the same distribution, without any influence from other values of \\(\\epsilon_j\\) for \\(j \\neq i\\).\nThe noise distribution we will usually consider is the Gaussian distribution, also called the Gaussian distribution.\n\n\n\n\n\n\n\n\n\nFigure 3.4: The probability that a Gaussian random variable lies between two values \\(a\\) and \\(b\\) is given by the area under its PDF between those values.\n\n\n\n\n\nDefinition 3.1 (Gaussian (Normal) Distribution) A random variable \\(\\epsilon\\) has a Gaussian distribution with parameters mean \\(\\mu\\) and standard deviation \\(\\sigma\\) if the probability that \\(\\epsilon\\) has a value between \\(a\\) and \\(b\\) is given by:\n\\[\n\\begin{aligned}\n    \\mathbb{P}(a \\leq \\epsilon \\leq b) = \\int_a^b p_\\epsilon(x;\\mu, \\sigma) \\, dx\\;,\n\\end{aligned}\n\\]\nwhere\n\\[\n\\begin{aligned}\np_\\epsilon(x;\\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\\;.\n\\end{aligned}\n\\]\nThe function \\(p_\\epsilon(x;\\mu, \\sigma)\\) is called the probability density function (PDF) of the Gaussian distribution. We use the shorthand notation \\(\\epsilon \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) to indicate that the random variable \\(\\epsilon\\) has a Gaussian distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nGaussian distributions are often called normal distributions in the statistics literature.\n\nHere’s a simple vectorized implementation of the Gaussian PDF, which can be evaluated on a PyTorch tensor of inputs:\n\npi = 3.141592653589793\ndef normal_pdf(x, mu, sigma):\n    return 1 / (sigma * (2 * pi)**0.5) * torch.exp(-0.5 * ((x - mu) / sigma) ** 2)\n\nnormal_pdf(torch.tensor([0.0, 1.0, 2.0]), mu=0.0, sigma=1.0)\n\ntensor([0.3989, 0.2420, 0.0540])\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.5: Normal distribution PDFs for different values.\n\n\n\n\nThe two parameters of the Gaussian distribution describe its “shape:” The mean \\(\\mu\\) indicates the “center” of the distribution, while the standard deviation \\(\\sigma\\) indicates how “spread out” the distribution is.\n“Gaussian noise” refers to random variables drawn from a Gaussian distribution. We can generate Gaussian noise from a given Gaussian distribution using many functions. We’ll focus on PyTorch’s implementation, which allows us to generate tensors of Gaussian noise easily:\n\nmu = 0.0\nsigma = 1.0\nepsilon = torch.normal(mu, sigma, size=(10,))\nepsilon\n\ntensor([ 0.4499,  1.8596, -0.5629,  1.0266,  0.2415, -0.7050,  0.2569,  0.1465,\n         0.0287, -2.3102])\n\n\nIf we take many samples of Gaussian noise and plot a histogram of their values, then we’ll find (via the law of large numbers) that the histogram approximates the PDF of the Gaussian distribution we sampled from, as illustrated in Figure 3.6:\n\n\n\n\n\n\n\n\n\nFigure 3.6: Histogram of samples from a Gaussian distribution compared to its PDF.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#properties-of-the-gaussian-distribution",
    "href": "chapters/02-signal-noise.html#properties-of-the-gaussian-distribution",
    "title": "3  Data = Signal + Noise",
    "section": "Properties of the Gaussian Distribution",
    "text": "Properties of the Gaussian Distribution\nThe Gaussian distribution has a number of useful properties for modeling noise in data. Here are a few:\n\nTheorem 3.1 (Translation) If \\(\\epsilon\\) is normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), then the random variable \\(\\epsilon + c\\) (where \\(c\\) is a constant) is normally distributed with mean \\(\\mu + c\\) and standard deviation \\(\\sigma\\). In other words, if \\(\\epsilon \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), then \\(\\epsilon + c \\sim \\mathcal{N}(\\mu + c, \\sigma^2)\\).\n\n\nTheorem 3.2 (Scaling) If \\(\\epsilon\\) is normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), then the random variable \\(a \\epsilon\\) (where \\(a\\) is a constant) is normally distributed with mean \\(a \\mu\\) and standard deviation \\(|a| \\sigma\\). In other words, if \\(\\epsilon \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), then \\(a \\epsilon \\sim \\mathcal{N}(a \\mu, (a \\sigma)^2)\\).\n\nThe expectation or mean of a continuous-valued random variable \\(\\epsilon\\) with probability density function \\(p_\\epsilon(x)\\) is defined as:\n\\[\n\\begin{aligned}\n    \\mathbb{E}[\\epsilon] = \\int_{-\\infty}^{\\infty} x \\, p_\\epsilon(x) \\, dx\\;.\n\\end{aligned}\n\\]\nThe variance of a continuous-valued random variable \\(\\epsilon\\) with probability density function \\(p_\\epsilon(x)\\) is defined as:\n\\[\n\\begin{aligned}\n    \\text{Var}(\\epsilon) = \\mathbb{E}[(\\epsilon - \\mathbb{E}[\\epsilon])^2] = \\int_{-\\infty}^{\\infty} (x - \\mathbb{E}[\\epsilon])^2 \\, p_\\epsilon(x) \\, dx\\;.\n\\end{aligned}\n\\]\nWe can interpret the variance as a measure of how far away \\(\\epsilon\\) “usually, on average” lies from its mean value.\n\nTheorem 3.3 (Mean and Variance of the Gaussian) For a normally distributed random variable with mean \\(\\mu\\) and standard deviation \\(\\sigma\\):\n\\[\n\\begin{aligned}\n    \\mathbb{E}[\\epsilon] &= \\mu \\\\\n    \\mathrm{Var}[\\epsilon] &= \\sigma^2.\n\\end{aligned}\n\\]\n\nThese two properties can be proven using some integration tricks which are beyond our scope here.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#the-standard-gaussian",
    "href": "chapters/02-signal-noise.html#the-standard-gaussian",
    "title": "3  Data = Signal + Noise",
    "section": "The Standard Gaussian",
    "text": "The Standard Gaussian\nThe standard Gaussian distribution is the Gaussian with mean zero and standard deviation one: \\(\\mathcal{N}(0, 1)\\). We often use the symbol \\(Z\\) to Due to the properties above, we can make any Gaussian random variable from a standard Gaussian: if \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), then, using Theorem 3.2 and Theorem 3.1, we can write \\(X\\) as\n\\[\n\\begin{aligned}\n    X \\sim \\sigma Z + \\mu\\;.\n\\end{aligned}\n\\]\nWe can check that this random variable has the correct mean and variance:\n\\[\n\\begin{aligned}\n    \\mathbb{E}[X] = \\mathbb{E}[\\sigma Z + \\mu] = \\sigma \\mathbb{E}[Z] + \\mu = \\sigma \\cdot 0 + \\mu = \\mu\\;,\n\\end{aligned}\n\\]\nwhere we’ve used linearity of expectation and the fact that \\(\\mathbb{E}[Z] = 0\\). To calculate the variance, we use the fact that \\(\\mathbb{E}[Z]= 0\\), again, so that\n\\[\n\\begin{aligned}\n    \\mathrm{Var}[X] = \\mathrm{Var}[\\sigma Z + \\mu] = \\mathrm{Var}[\\sigma Z] = \\sigma^2 \\mathrm{Var}[Z] = \\sigma^2 \\cdot 1 = \\sigma^2\\;.\n\\end{aligned}\n\\]\n\n\nWe’ve used the variance properties\n\\[\n\\begin{aligned}\n    \\mathrm{Var}[aX] = a^2\\mathrm{Var}[X]& \\\\\n    \\mathrm{Var}[X + b] = \\mathrm{Var}[X]&\\;\n\\end{aligned}\n\\]\nfor constants \\(a\\) and \\(b\\).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#gaussian-noise",
    "href": "chapters/02-signal-noise.html#gaussian-noise",
    "title": "3  Data = Signal + Noise",
    "section": "Gaussian Noise",
    "text": "Gaussian Noise\nWith the Gaussian distribution in mind, let’s now return to our signal-plus-noise paradigm:\n\\[\n\\begin{aligned}\n    y_i = f(x_i) + \\epsilon_i\\;,\n\\end{aligned}\n\\]\nIf we assume that \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\) (i.e., that the noise terms are independent and identically distributed Gaussian random variables with mean zero and standard deviation \\(\\sigma\\)), then we can use the translation property of the Gaussian distribution (Theorem 3.1) to deduce that\n\\[\n\\begin{aligned}\n    y_i &\\sim \\mathcal{N}(f(x_i), \\sigma^2)\\;.\n\\end{aligned}\n\\tag{3.2}\\]\nSo, we are modeling each data point \\(y_i\\) as a Gaussian random variable whose mean is given by the underlying signal \\(f(x_i)\\), and whose standard deviation is given by the noise level \\(\\sigma\\). This modeling approach is important enough to merit a name: Technically, the model described below is an additive Gaussian model, but we won’t worry about non-additive models here and therefore won’t bother repeating “additive.”\n\nDefinition 3.2 (Gaussian Model) The model\n\\[\n\\begin{aligned}\n    y &= f(x_i) + \\epsilon_i \\\\    \n    \\epsilon_i &\\sim \\mathcal{N}(0, \\sigma^2)\n\\end{aligned}\n\\tag{3.3}\\]\nis called a Gaussian data generating model.\n\nOften, as illustrated so far in these notes, we choose \\(f\\) to be a linear function of \\(x_i\\):\n\nDefinition 3.3 (Linear-Gaussian Model) A Gaussian model in which\n\\[\n\\begin{aligned}\n    f(x_i) = w_0 + w_1 x_i   \n\\end{aligned}\n\\tag{3.4}\\]\nfor parameters \\(w_0, w_1 \\in \\mathbb{R}\\) is called a (1-dimensional) linear-Gaussian model.\n\nHere’s a schematic picture of the linear-Gaussian model.\n\nCode\n# from https://stackoverflow.com/questions/47597119/plot-a-vertical-normal-distribution-in-python\ndef draw_gaussian_at(support, sd=1.0, height=1.0, \n        xpos=0.0, ypos=0.0, ax=None, **kwargs):\n    if ax is None:\n        ax = plt.gca()\n    gaussian = torch.exp((-support ** 2.0) / (2 * sd ** 2.0))\n    gaussian /= gaussian.max()\n    gaussian *= height\n    return ax.plot(gaussian + xpos, support + ypos, **kwargs)\n    \nsupport = torch.linspace(-10, 10, 1000)\nfig, ax = plt.subplots()\n\nax.plot(x, signal, color = \"black\", linestyle = \"--\", label = r\"Signal: $f(x_i) = 2x_i + 1$\")\n\nfor each in x:\n    draw_gaussian_at(support, sd=3, height=0.4, xpos=each, ypos=2.0 * each + 1.0, ax=ax, color='C0', alpha=0.4)\n\nax.scatter(x.numpy(), y.numpy(), **scatterplot_kwargs)\n\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$y$\")\nplt.title(\"Data points modeled as Gaussians around the signal\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.7: Illustration of the Gaussian noise model Equation 3.2, showing data points (black circles) as samples from Gaussian distributions (blue curves) centered on the signal (dashed line).\n\n\n\nWe are modeling \\(y_i\\) as a noisy sample from a Gaussian distribution centered at the signal value \\(f(x_i)\\), with noise level \\(\\sigma\\) controlling how spread out the distribution is. A larger value of \\(\\sigma\\) means that the observed data points \\(y_i\\) will tend to be further away from the signal \\(f(x_i)\\), while a smaller value of \\(\\sigma\\) means that the data points will tend to be closer to the signal. Larger values of the noise level \\(\\sigma\\) create noisier data sets where it is more difficult to discern the underlying signal.\n\nData Generating Distributions\nOne of the primary reasons to define models like Equation 3.2 is that they give us principled ways for thinking about what our models should learn – the signal – and what they should ignore – the noise. These models are also very helpful as models of where the data comes from – that is, as data generating distributions.\n\nDefinition 3.4 (Data Generating Distribution) A data generating distribution (also called a data generating model) is a probabilistic model that describes how data points (especially targets \\(y\\)) are generated in terms of random variables and their distributions.\n\nThe linear-Gaussian model is a simple example of a data generating model: it describes a recipe to simulate each target \\(y_i\\) by first computing the signal value \\(f(x_i)\\), then sampling a noise term \\(\\epsilon_i\\) from a Gaussian distribution, and finally adding the two together to get \\(y_i = f(x_i) + \\epsilon_i\\).\nA very useful feature of data generating models is that they also give us tools to measure how well our learned signal fits observed data, via the concept of a likelihood.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/02-signal-noise.html#model-likelihood",
    "href": "chapters/02-signal-noise.html#model-likelihood",
    "title": "3  Data = Signal + Noise",
    "section": "Model Likelihood",
    "text": "Model Likelihood\nGiven a data-generating distribution, we can compute the likelihood of the observed data under that model. Recall that the PDF of a single data point \\(y_i\\) under the Gaussian noise model Equation 3.2 with predictor value \\(x_i\\) is given by the formula\n\\[\n\\begin{aligned}\n    p_{y}(y_i; f(x_i), \\sigma^2) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{(y_i - f(x_i))^2}{2\\sigma^2}\\right)\\;.\n\\end{aligned}\n\\]\nThe likelihood of the complete data set is simply the product of the individual data point PDFs, evaluated at their corresponding observed values. The likelihood is a function of the predictors which we’ll collect into a vector $= (x_1,,x_n)^T, the targets which we’ll collect into a vector $ \\(\\mathbf{y}= (y_1,\\ldots,y_n)^T\\), and the parameters of the model (in this case, the function \\(f\\) and the noise level \\(\\sigma\\)):\n\nDefinition 3.5 (Gaussian Likelihood, Log-Likelihood) The likelihood of the observed data \\((\\mathbf{x}, \\mathbf{y})\\) under a 1d Gaussian model with function \\(f\\) and noise level \\(\\sigma\\) is given by:\n\\[\n\\begin{aligned}\n    L(\\mathbf{x}, \\mathbf{y}; f, \\sigma) = \\prod_{i = 1}^n p_{y}(y_i; f(x_i), \\sigma^2)\n\\end{aligned}\n\\]\nThe log-likelihood is the logarithm of the likelihood:\n\\[\n\\begin{aligned}\n    \\mathcal{L}(\\mathbf{x}, \\mathbf{y}; f, \\sigma) = \\log L(\\mathbf{x}, \\mathbf{y}; f, \\sigma) = \\sum_{i = 1}^n \\log p_{y}(y_i; f(x_i), \\sigma^2)\\;.\n\\end{aligned}\n\\tag{3.5}\\]\n\nThe log-likelihood \\(\\mathcal{L}\\) in Equation 3.5 is almost always the tool we work with in applied contexts – it turns products into sums, which is very useful in computational practice.\n\nA First Look: Likelihood Maximization\nLet’s now finally fit a machine learning model! We’ll assume that the data is sampled from the linear-Gaussian model specified by Equation 3.3 and Equation 3.4, and try to fit the parameters \\(w_0, w_1\\) of the function \\(f\\) to maximize the likelihood of the observed data. For now, we’ll do this simply by choosing the combination of parameters that achieves the best likelihood from among many candidates:\nTo see how the likelihood can give us a tool to assess model fit, we can compute the likelihood of our observed data for different choices of the function \\(f\\). This can be done in a simple grid search over possible values of the parameters \\(w_0, w_1\\) in the linear function \\(f(x) = w_0 + w_1 x\\).\n\nsig = 3.0  # assumed noise level\n1best_ll = -float('inf')\nbest_w = None\n\nfor w0 in torch.linspace(-5, 5, 20):\n    for w1 in torch.linspace(-1, 3, 20):\n2        f = lambda x: w0 + w1 * x\n        ll = 0.0\n3        ll += normal_pdf(y, f(x), sig).log().sum().item()\n\n4        if ll &gt; best_ll:\n            best_ll = ll\n            best_w = (w0.item(), w1.item())\n\n\n1\n\nInitialize the best log-likelihood and best parameters.\n\n2\n\nDefine the predictor function \\(f\\) with current parameters.\n\n3\n\nCompute the data log-likelihood. The normal_pdf function computes the PDF values for all data points at once, which we then log and sum to get the log-likelihood.\n\n4\n\nUpdate the best log-likelihood and parameters if the current log-likelihood is better.\n\n\n\n\nLet’s check the predictor function \\(f\\) we learned by heuristically maximizing the log-likelihood against the observed data:\n\nCode\nfig, ax = plt.subplots(figsize = (6, 4))\n\nax.scatter(x.numpy(), y.numpy(), **scatterplot_kwargs)\nax.plot(x.numpy(), (best_w[0] + best_w[1] * x).numpy(), color = \"firebrick\", linestyle = \"--\", label = r\"$f(x) = w_0 + w_1 x$\")\n\nax.plot(x.numpy(), signal.numpy(), color = \"black\", linestyle = \"--\", label = r\"True signal: $f(x) = 2x + 1$\")\nax.set(xlabel = r\"$x$\", ylabel = r\"$y$\")\nplt.legend()\nplt.title(fr\"Best LL: {best_ll:.2f}   $w_1 = {best_w[1]:.2f}, w_0 = {best_w[0]:.2f}$\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.8: Comparison of the true signal (black dashed line) and the model fit by maximizing the likelihood (red dashed line).\n\n\n\nThe model we selected via our maximum likelihood grid-search agrees relatively closely with the true underlying signal.\nSoon, we’ll learn how to use the likelihood as a method to learn the function \\(f\\) more systematically from data.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data = Signal + Noise</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html",
    "href": "chapters/03-maximum-likelihood.html",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "",
    "text": "Recap: Log-Likelihood of the Linear-Gaussian Model\nOpen the live notebook in Google Colab or download the live notebook.\nRecap recap recap\n© Phil Chodrow, 2025",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#the-gradient-of-a-multivariate-function",
    "href": "chapters/03-maximum-likelihood.html#the-gradient-of-a-multivariate-function",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "The Gradient of a Multivariate Function",
    "text": "The Gradient of a Multivariate Function\n\n\nAs you can study in courses dedicated to multivariable calculus, the existence of all of a function’s partial derivatives does not necessarily imply that the function is multivariate differentiable. In this course, we’ll exclusively treat functions which are indeed multivariate differentiable unless otherwise noted, and so this distinction will not be an issue for us.\n\nDefinition 4.1 Let \\(f:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\) be a function which accepts a vector input \\(\\mathbf{w}=(w_1,\\ldots,w_p)^T\\in \\mathbb{R}^p\\) and returns a scalar output \\(f(\\mathbf{w})\\in \\mathbb{R}\\). The partial derivative of \\(f\\) with respect to the \\(j\\)-th coordinate \\(w_j\\) is defined as the limit\n\\[\n\\begin{aligned}\n    \\frac{\\partial f}{\\partial w_i} &= \\lim_{h \\rightarrow 0} \\frac{f(w_1,\\ldots,w_i + h, \\ldots w_p) - f(w_1,\\ldots,w_i, \\ldots w_p)}{h} \\\\\n    &= \\lim_{h \\rightarrow 0} \\frac{f(\\mathbf{w}+ h\\mathbf{e}_i) - f(\\mathbf{w})}{h}\\;,\n\\end{aligned}\n\\]\nwhere \\(\\mathbf{e}_i = (0,0,\\ldots,1,\\ldots,0,0)^T\\) is the \\(i\\)-th standard basis vector in \\(\\mathbb{R}^p\\), i.e., the vector with a 1 in the \\(i\\)-th position and 0’s elsewhere. If this limit does not exist, then the partial derivative is said to be undefined.\n\nJust like in single-variable calculus, it’s not usually convenient to work directly with the limit definition of the partial derivative. Instead we use the following heuristic:\n\nProposition 4.1 To compute \\(\\frac{\\partial f}{\\partial w_i}\\), treat all other variables \\(w_j\\) for \\(j\\neq i\\) as constants, and differentiate \\(f\\) with respect to \\(w_i\\) using the usual rules of single-variable calculus (power rule, product rule, chain rule, etc.).\n\n\nExercise 4.1 (Practice with Partial Derivatives) Let \\(f:\\mathbb{R}^3\\rightarrow \\mathbb{R}\\) be defined by \\(f(x,y,z) = x^2\\sin y + yz + z^3x\\). Compute \\(\\frac{\\partial f}{\\partial x}\\), \\(\\frac{\\partial f}{\\partial y}\\), and \\(\\frac{\\partial f}{\\partial z}\\).\n\n\n\n\n\n\n\nSolSolution for Exercise 4.1\n\n\n\n\n\nTo compute \\(\\frac{\\partial f}{\\partial x}\\), we treat \\(y\\) and \\(z\\) as constants, which yields\n\\[\n\\frac{\\partial f}{\\partial x} = 2x \\sin y + z^3\\;.\n\\]\nSimilarly, we can compute \\(\\frac{\\partial f}{\\partial y}\\) and \\(\\frac{\\partial f}{\\partial z}\\):\n\\[\n\\begin{align}\n    \\frac{\\partial f}{\\partial y} &= x^2 \\cos y + z \\\\\n    \\frac{\\partial f}{\\partial z} &= y + 3z^2 x\\;.    \n\\end{align}\n\\]\n\n\n\n\nExercise 4.2 (Partial Derivatives of the Gaussian Log-Likelihood) Suppose we have \\(n\\) independent and identically-distributed samples \\(x_1,\\ldots,x_n\\) from a Gaussian distribution with unknown mean \\(\\mu\\) and known variance \\(\\sigma^2\\). The log-likelihood function for this data is\n\\[\n\\begin{aligned}\n    \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu) &= \\sum_{i=1}^n \\log p(x_i;\\sigma^2,\\mu) \\\\\n    &= \\sum_{i=1}^n \\log \\left( \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left( -\\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\right) \\\\\n    &= \\sum_{i=1}^n \\left( -\\frac{1}{2} \\log(2\\pi \\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2} \\right) \\\\\n    &= -\\frac{n}{2} \\log(2\\pi \\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\;.\n\\end{aligned}\n\\]\nCompute \\(\\frac{\\partial \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)}{\\partial \\mu}\\), the partial derivative of the log-likelihood with respect to the mean parameter \\(\\mu\\), and compute \\(\\frac{\\partial \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)}{\\partial \\sigma^2}\\), the partial derivative with respect to the variance parameter \\(\\sigma^2\\). (Here, treat \\(\\sigma^2\\) as a single variable, not \\(\\sigma\\).)\n\n\n\n\n\n\n\nSolSolution for Exercise 4.2\n\n\n\n\n\nTo calculate \\(\\frac{\\partial \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)}{\\partial \\mu}\\), we’ll first treat \\(\\sigma^2\\) (and all the \\(x_i\\)’s) as constants and differentiate with respect to \\(\\mu\\). The first term in the log-likelihood does not depend on \\(\\mu\\), so its derivative is zero. For the second term, we need to use the chain rule:\n\\[\n\\begin{aligned}\n    \\frac{\\partial \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)}{\\partial \\mu} &= -\\frac{1}{2\\sigma^2} \\cdot \\frac{\\partial}{\\partial \\mu} \\left( \\sum_{i=1}^n (x_i - \\mu)^2 \\right) \\\\\n    &= -\\frac{1}{2\\sigma^2} \\cdot  \\left( \\sum_{i=1}^n \\frac{\\partial}{\\partial \\mu}(x_i - \\mu)^2 \\right) \\\\\n    &= -\\frac{1}{2\\sigma^2} \\cdot \\sum_{i=1}^n 2(x_i - \\mu)(-1) \\\\\n    &= \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)\\;.\n\\end{aligned}\n\\]\nNext we need to compute \\(\\frac{\\partial \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)}{\\partial \\sigma^2}\\). This time, we treat \\(\\mu\\) (and all the \\(x_i\\)’s) as constants and differentiate with respect to \\(\\sigma^2\\). We again use the chain rule:\n\\[\n\\begin{aligned}\n    \\frac{\\partial \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)}{\\partial \\sigma^2} &= -\\frac{n}{2} \\cdot \\frac{\\partial}{\\partial \\sigma^2} \\log(2\\pi \\sigma^2) - \\frac{1}{2} \\cdot \\frac{\\partial}{\\partial \\sigma^2} \\left( \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2 \\right) \\\\\n    &= -\\frac{n}{2} \\cdot \\frac{1}{2\\pi \\sigma^2} \\cdot 2\\pi - \\frac{1}{2} \\cdot \\left( -\\frac{1}{(\\sigma^2)^2} \\sum_{i=1}^n (x_i - \\mu)^2 \\right) \\\\\n    &= -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i=1}^n (x_i - \\mu)^2\\;.\n\\end{aligned}\n\\]\n\n\n\n\nDefinition 4.2 Let \\(f:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\) be a differentiable function which accepts a vector input \\(\\mathbf{w}=(w_1,\\ldots,w_p)^T\\in \\mathbb{R}^p\\) and returns a scalar output \\(f(\\mathbf{w})\\in \\mathbb{R}\\). The gradient of \\(f\\) at \\(\\mathbf{w}\\), written \\(\\nabla f(\\mathbf{w}) \\in \\mathbb{R}^p\\), is the vector of partial derivatives\n\\[\n\\begin{align}\n    \\nabla f(\\mathbf{w}) &= \\begin{pmatrix}\n    \\frac{\\partial f}{\\partial w_1} \\\\\n    \\frac{\\partial f}{\\partial w_2} \\\\\n    \\vdots \\\\\n    \\frac{\\partial f}{\\partial w_p}\n    \\end{pmatrix}\\;.\n\\end{align}\n\\]\n\n\nExercise 4.3 (Writing Gradients) Write the gradient of the function in Exercise 4.1.\n\n\n\n\n\n\n\nSolSolution for Exercise 4.3\n\n\n\n\n\nIn the function from Exercise 4.1, the gradient is given by stacking the partial derivatives we computed into a single vector:\n\\[\n\\begin{aligned}\n    \\nabla f(x, y, z) =\n     \\begin{pmatrix}\n    \\frac{\\partial f}{\\partial x} \\\\\n    \\frac{\\partial f}{\\partial y} \\\\\n    \\frac{\\partial f}{\\partial z}\n    \\end{pmatrix} &=\n    \\begin{pmatrix}\n    2x \\sin y + z^3 \\\\\n    x^2 \\cos y + z \\\\\n    y + 3z^2 x  \n    \\end{pmatrix}\n    \\in \\mathbb{R}^3\\;.\n\\end{aligned}\n\\]\n\n\n\n\nExercise 4.4 (Gradient of the Gaussian Log-Likelihood) Write the gradient of the Gaussian log-likelihood function in Exercise 4.2.\n\n\n\n\n\n\n\nSolSolution for Exercise 4.4\n\n\n\n\n\nFor the likelihood of the Gaussian from Exercise 4.2, the gradient is given by\n\\[\n\\begin{aligned}\n    \\nabla \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu) =\n     \\begin{pmatrix}\n    \\frac{\\partial \\mathcal{L}}{\\partial \\mu} \\\\\n    \\frac{\\partial \\mathcal{L}}{\\partial \\sigma^2}\n    \\end{pmatrix} &=\n    \\begin{pmatrix}\n    \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu) \\\\\n    -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i=1}^n (x_i - \\mu)^2\n    \\end{pmatrix}\n    \\in \\mathbb{R}^2\\;.\n\\end{aligned}\n\\]\n\n\n\n\nThe Gradient Points In the Direction of Greatest Increase\nAn important feature of the gradient is that it tells us the direction in which a small change in the function inputs \\(\\mathbf{w}\\) could produce the greatest increase in the function output \\(f(\\mathbf{w})\\). Here’s an example using the Gaussian likelihood from Exercise 4.2 and Exercise 4.4:\nTODO: HAS SOME ISSUES\n\nimport torch\nfrom matplotlib import pyplot as plt\n\nmu_grid = torch.linspace(-1, 1, 100)\nsigma2_grid = torch.linspace(0.1, 2, 100)\nMU, SIGMA2 = torch.meshgrid(mu_grid, sigma2_grid, indexing='ij')\ndata = torch.tensor([0.5, -1.0, 1.0, 0.7, 0.3])  # example data points\n\ndef gaussian_log_likelihood(mu, sigma2, data):\n    n = data.shape[0]\n    sum_term = 0\n    for x in data:\n        sum_term += (x - mu) ** 2\n\n    ll = -n / 2 * torch.log(2 * torch.pi * sigma2) - 1 / (2 * sigma2) * sum_term\n    return ll\n\nLL = gaussian_log_likelihood(MU, SIGMA2, data)\n\nfig, ax = plt.subplots()\n\nim = ax.contourf(LL.numpy(), levels=50, cmap='inferno')\n\nax.set_yticks([0, 25, 50, 75, 99], labels=[f\"{v:.2f}\" for v in mu_grid[[0, 25, 50, 75, 99]]])\nax.set_xticks([0, 25, 50, 75, 99], labels=[f\"{v:.2f}\" for v in sigma2_grid[[0, 25, 50, 75, 99]]])\nax.set_ylabel(r'Mean ($\\mu$)')\nax.set_xlabel(r'Variance ($\\sigma^2$)')\n\ni, j = 50, 50  # point at which to compute gradient\nmu_point = MU[i, j]\nsigma2_point = SIGMA2[i, j]\n\nmu_point.requires_grad_()\nsigma2_point.requires_grad_()\n\nll_point = gaussian_log_likelihood(mu_point, sigma2_point, data)\nll_point.backward()\n\n\nax.annotate(\n    'Gradient Vector',\n    xy=(i+5*sigma2_point.grad.detach().numpy(),j+5*mu_point.grad.detach().numpy()),\n    xytext=(i,j),\n    arrowprops=dict(facecolor='white', arrowstyle='-&gt;', lw=1.5, color='white'), \n    xycoords='data',\n)\n\nplt.colorbar(im)\nax.set_title('Gradient of Gaussian Log-Likelihood at a Point')\nplt.show()\n\n/var/folders/xn/wvbwvw0d6dx46h9_2bkrknnw0000gn/T/ipykernel_47294/2548378075.py:40: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  ax.annotate(\n\n\n\n\n\n\n\n\n\n\n\nChecking Gradients with torch\nThe pytorch package, which we’ll use throughout this course, implements automatic differentiation. Automatic differentiation is an extraordinarily powerful tool which we’ll study later in the course. For now, we’ll just note that it provides a handy way to check calculations of derivatives and gradients. For example, we can use torch to check the gradient we computed in Exercise 4.3 as follows:\n\nimport torch\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n\n# function to differentiate\nf = lambda x: x[0]**2 * torch.sin(x[1]) + x[1]*x[2] + x[2]**3 * x[0]\n\n# compute the gradient by hand using the formula we derived\nour_grad = torch.tensor([\n    2 * x[0] * torch.sin(x[1]) + x[2]**3,\n    x[0]**2 * torch.cos(x[1]) + x[2],\n    x[1] + 3 * x[2]**2 * x[0]\n])\nprint(our_grad)\n\n# compute the gradient using automatic differentiation\n1y = f(x)\n2y.backward()\n3print(x.grad)\n\n\n1\n\nFirst, we compute the value of the function we want to differentiate and store the result to a variable (in this case called y).\n\n2\n\nNext, we call the backward() method on y, which computes the gradient of y with respect to its inputs (in this case, the vector x) using automatic differentiation.\n\n3\n\nFinally, we can access the computed gradient via the grad attribute of the input tensor x.\n\n\n\n\ntensor([28.8186,  2.5839, 29.0000])\ntensor([28.8186,  2.5839, 29.0000])\n\n\nThe two approaches agree! As we grow comfortable with the calculus, we’ll begin to rely more on torch’s automatic differentiation capabilities to compute gradients for us.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#critical-points-and-local-extrema",
    "href": "chapters/03-maximum-likelihood.html#critical-points-and-local-extrema",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "Critical Points and Local Extrema",
    "text": "Critical Points and Local Extrema\nOne way we can use gradients is by analytically computing the local extrema of a function: solve the equation \\(\\nabla \\mathcal{L}(\\mathbf{w}) = 0\\) for \\(\\mathbf{w}\\) to find critical points of the log-likelihood, and then check which of these points are local maxima.\nA critical point of a multivariate function is a point at which all of its partial derivatives are equal to zero. Critical points are candidates for local maxima or minima of the function, and so they are of interest when performing maximum-likelihood estimation by solving \\(\\nabla \\mathcal{L}(\\mathbf{w}) = 0\\).\n\nDefinition 4.3 (Critical Points of Multivariate Functions) A critical point of a differentiable function \\(f:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\) is a point \\(\\mathbf{w}^* \\in \\mathbb{R}^p\\) such that \\(\\nabla f(\\mathbf{w}^*) = \\mathbf{0}\\) (the zero vector in \\(\\mathbb{R}^p\\)).\n\nAll critical points of a function can be identified by solving the system of equations \\(\\nabla f(\\mathbf{w}) = \\mathbf{0}\\). In a few rare cases, it’s possible to solve this system analytically to find all critical points.\n\n\nThe notation \\(\\lVert \\mathbf{v} \\rVert_2\\) refers to the Euclidean norm of \\(\\mathbf{v}\\), with formula\n\\[\n\\begin{aligned}\n    \\lVert \\mathbf{v} \\rVert_2 = \\sqrt{\\sum_{i = 1}^p v_i^2}\\;.\n\\end{aligned}\n\\]\n\nDefinition 4.4 (Local Minima and Maxima) A local minimum of a differentiable function \\(f:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\) is a point \\(\\mathbf{w}^* \\in \\mathbb{R}^p\\) such that there exists some radius \\(r&gt;0\\) such that for all \\(\\mathbf{w}\\) with \\(\\|\\mathbf{w}- \\mathbf{w}^*\\|_2 &lt; r\\), we have \\(f(\\mathbf{w}) \\geq f(\\mathbf{w}^*)\\). A local maximum is defined similarly, with the inequality reversed: for all \\(\\mathbf{w}\\) with \\(\\|\\mathbf{w}- \\mathbf{w}^*\\|_2 &lt; r\\), we have \\(f(\\mathbf{w}) \\leq f(\\mathbf{w}^*)\\).\n\n\n\nThe Mild Conditions of Theorem 4.1 are that \\(f\\) is continuously differentiable in an open neighborhood around \\(\\mathbf{w}^*\\).\n\nTheorem 4.1 (Local Extrema are Critical Points) Under Mild Conditions*, if \\(\\mathbf{w}^*\\) is a local extremum (minimum or maximum) of a differentiable function \\(f:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\), then \\(\\mathbf{w}^*\\) is a critical point of \\(f\\).\n\n\n\n\n\n\n\nNoteWe Always Minimize\n\n\n\nAlthough our motivating problem is still maximum likelihood estimation, it is conventional in the literature on statistics, machine learning, and optimization to always seek minima of a given function. This works because maximizing \\(\\mathcal{L}(\\mathbf{w})\\) is equivalent to minimizing \\(-\\mathcal{L}(\\mathbf{w})\\). Therefore, in the remainder of this chapter and in subsequent chapters, we will often refer to “minimizing the negative log-likelihood” rather than “maximizing the log-likelihood.” Perhaps confusingly, we’ll still refer to the result as the “maximum likelihood estimate” (MLE).\n\n\nTheorem 4.1 tells us that we can try to find the maximum likelihood estimate of a parameter vector \\(\\mathbf{w}\\) by solving the equation \\(\\nabla \\mathcal{L}(\\mathbf{w}) = \\mathbf{0}\\). In principle, we should then check that the critical points we find are indeed minima of \\(-\\mathcal{L}(\\mathbf{w})\\) rather than maxima or saddle points, which can sometimes be done using the multivariate second-derivative test. In practice, however, this second step is often skipped. Skipping the second-derivative test can be justified if it is known that \\(-\\mathcal{L}\\) is a convex function.\nEquipped with the concept of critical points, we are ready to find maximum likelihood estimates by solving the equation \\(\\nabla \\mathcal{L}(\\mathbf{w}) = \\mathbf{0}\\).\n\nExercise 4.5 (Estimating Gaussian Parameters) Using the gradient \\(\\nabla \\mathcal{L}(\\mathbf{x};\\sigma^2,\\mu)\\) computed in Exercise 4.4, find the maximum likelihood estimates for the mean \\(\\mu\\) and variance \\(\\sigma^2\\) of a Gaussian distribution given \\(n\\) independent and identically-distributed samples \\(x_1,\\ldots,x_n\\).\n\n\n\n\n\n\n\nSolSolution for Exercise 4.5\n\n\n\n\n\nWe can find the critical points of the log-likelihood by solving the system of equations given by setting each component of the gradient to zero:\n\\[\n\\begin{align}\n    \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu) &= 0 \\\\\n    -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2}  \\sum_{i=1}^n (x_i - \\mu)^2 &= 0\\;.    \n\\end{align}\n\\]\nSolving the first equation for \\(\\mu\\), we find\n\\[\n\\begin{aligned}\n    \\frac{1}{\\sigma^2} \\sum_{i = 1}^n x_i - \\frac{1}{\\sigma^2} \\mu = 0 &\\implies \\sum_{i=1}^n x_i = n \\mu \\implies \\mu = \\frac{1}{n} \\sum_{i=1}^n x_i\\;.\n\\end{aligned}\n\\]\nWe can now solve for \\(\\sigma^2\\) using this value of \\(\\mu\\) in the second equation:\n\\[\n\\begin{aligned}\n    -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i=1}^n (x_i - \\mu)^2 &= 0 \\\\\n    \\implies \\frac{1}{2(\\sigma^2)^2} \\sum_{i=1}^n (x_i - \\mu)^2 &= \\frac{n}{2\\sigma^2} \\\\\n    \\implies \\sum_{i=1}^n (x_i - \\mu)^2 &= n \\sigma^2 \\\\\n    \\implies \\sigma^2 &= \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2\\;.\n\\end{aligned}\n\\]\n\n\n\nBy convention, the maximum-likelihood estimate of a parameter is given a “hat” symbol, so we would write the MLE estimators we found above as \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}^2\\).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#gradient-of-the-linear-gaussian-log-likelihood",
    "href": "chapters/03-maximum-likelihood.html#gradient-of-the-linear-gaussian-log-likelihood",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "Gradient of the Linear-Gaussian Log-Likelihood",
    "text": "Gradient of the Linear-Gaussian Log-Likelihood\nLet’s now consider the linear-Gaussian model from last chapter. In this model, we assume that each observed target variable \\(y_i\\) is sampled from a Gaussian distribution with mean equal to a linear function of the corresponding feature vector \\(x_i\\):\n\\[\n\\begin{aligned}\n    y_i &\\sim \\mathcal{N}(w_1 x_i + w_0, \\sigma^2)\\;,\n\\end{aligned}\n\\]\nTo find the maximum-likelihood estimates given a data set of pairs \\((x_i,y_i)\\) for \\(i=1,\\ldots,n\\), we need to compute the log-likelihood function for this model, which as per last chapter is\n\\[\n\\begin{aligned}\n    \\mathcal{L}(\\mathbf{x}, \\mathbf{y}; w_1, w_0) &= \\sum_{i = 1}^n \\log p_y(y_i;w_1x_i + w_0; \\sigma^2) \\\\\n    &= \\sum_{i = 1}^n \\log \\left( \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left( -\\frac{(y_i - (w_1 x_i + w_0))^2}{2\\sigma^2} \\right) \\right) \\\\\n    &= \\sum_{i = 1}^n \\left( -\\frac{1}{2} \\log(2\\pi \\sigma^2) - \\frac{(y_i - (w_1 x_i + w_0))^2}{2\\sigma^2} \\right) \\\\\n    &= \\underbrace{-\\frac{n}{2} \\log(2\\pi \\sigma^2)}_{C} - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - (w_1 x_i + w_0))^2 \\\\\n    &= C - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - w_1 x_i - w_0)^2\\;.\n\\end{aligned}\n\\]\nWe’ve collected the terms that do not depend on \\(w_0\\) or \\(w_1\\) into a constant \\(C\\) to simplify the expression. We observe that to maximize the log-likelihood with respect to \\(w_0\\) and \\(w_1\\), we can equivalently minimize the mean-squared error \\(R(\\mathbf{x}, \\mathbf{y}; w_0, w_1) = \\frac{1}{n}\\sum_{i=1}^n (y_i - w_1 x_i - w_0)^2\\).  So, to find \\(\\hat{w}_0\\) and \\(\\hat{w}_1\\), we can solve the system of equations given by setting the gradient of the negative log-likelihood to zero:It’s conventional to normalize the sum appearing in the final line by the constant \\(\\frac{1}{n}\\).\n\\[\n\\begin{aligned}\n    \\nabla R(\\mathbf{x}, \\mathbf{y}; w_0, w_1) &= \\mathbf{0}\\;.\n\\end{aligned}\n\\]\n\nExercise 4.6 Compute the gradient \\(\\nabla R(\\mathbf{x}, \\mathbf{y}; w_0, w_1)\\) of the sum of squared errors for the linear-Gaussian model with respect to the parameters \\(w_0\\) and \\(w_1\\).\n\n\n\n\n\n\n\nSolSolution for Exercise 4.6\n\n\n\n\n\nWe have\n\\[\n\\begin{aligned}\n    \\frac{\\partial R}{\\partial w_0} = \\frac{1}{n} \\sum_{i=1}^n 2(y_i - w_1 x_i - w_0)(-1) &= -\\frac{2}{n} \\sum_{i=1}^n (y_i - w_1 x_i - w_0) \\\\\n\\end{aligned}\n\\]\nand\n\\[\n\\begin{aligned}\n    \\frac{\\partial R}{\\partial w_1} = \\frac{1}{n} \\sum_{i=1}^n 2(y_i - w_1 x_i - w_0)(-x_i) &= -\\frac{2}{n} \\sum_{i=1}^n x_i (y_i - w_1 x_i - w_0)\\;.\n\\end{aligned}\n\\]\n\n\n\n\nExercise 4.7 Compute the maximum-likelihood estimates \\(\\hat{w}_0\\) and \\(\\hat{w}_1\\) for the linear-Gaussian model by solving the system of equations given by setting the gradient computed in Exercise 4.6 to zero.\n\n\n\n\n\n\n\nSolSolution for Exercise 4.7\n\n\n\n\n\nWe’ll start with the first equation and solve for \\(\\hat{w}_0\\):\n\\[\n\\begin{aligned}\n    \\frac{\\partial R}{\\partial w_0} = -\\frac{2}{n} \\sum_{i=1}^n (y_i - \\hat{w}_1 x_i - \\hat{w}_0) &= 0 \\\\\n    \\implies \\sum_{i=1}^n y_i - \\hat{w}_1 \\sum_{i=1}^n x_i - n \\hat{w}_0 &= 0 \\\\\n    \\implies n \\hat{w}_0 &= \\sum_{i=1}^n y_i - \\hat{w}_1 \\sum_{i=1}^n x_i \\\\\n    \\implies\\hat{w}_0 &= \\frac{1}{n} \\sum_{i=1}^n y_i - \\hat{w}_1 \\frac{1}{n} \\sum_{i=1}^n x_i \\\\\n    &= \\bar{y} - \\hat{w}_1 \\bar{x}\\;,\n\\end{aligned}\n\\]\nwhere we’ve defined \\(\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i\\) and \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) to be the sample means of the \\(y_i\\)’s and \\(x_i\\)’s, respectively.\nNow we need to solve for \\(\\hat{w}_1\\) using this value of \\(\\hat{w}_0\\) in the second equation:\n\\[\n\\begin{aligned}\n    \\frac{\\partial R}{\\partial w_1} = -\\frac{2}{n} \\sum_{i=1}^n x_i (y_i - \\hat{w}_1 x_i - \\hat{w}_0) &= 0 \\\\\n    \\implies -\\frac{2}{n} \\sum_{i=1}^n x_i (y_i - \\hat{w}_1 x_i - \\bar{y} + \\hat{w}_1 \\bar{x}) &= 0 \\\\\n    \\implies -\\frac{2}{n} \\sum_{i=1}^n x_i (y_i - \\bar{y} + \\hat{w}_1 (\\bar{x} - x_i)) &= 0 \\\\\n    \\implies \\sum_{i=1}^n x_i (y_i - \\bar{y}) + \\hat{w}_1 \\sum_{i=1}^n x_i (\\bar{x} - x_i) &= 0 \\\\\n    \\implies \\hat{w}_1 \\sum_{i=1}^n x_i (\\bar{x} - x_i) &= - \\sum_{i=1}^n x_i (y_i - \\bar{y}) \\\\\n    \\implies \\hat{w}_1 &= \\frac{- \\sum_{i=1}^n x_i (y_i - \\bar{y})}{\\sum_{i=1}^n x_i (\\bar{x} - x_i)} \\\\\n    &= \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\\n\\end{aligned}\n\\]",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#a-first-look-gradient-descent-for-maximum-likelihood-estimation",
    "href": "chapters/03-maximum-likelihood.html#a-first-look-gradient-descent-for-maximum-likelihood-estimation",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "A First Look: Gradient Descent for Maximum Likelihood Estimation",
    "text": "A First Look: Gradient Descent for Maximum Likelihood Estimation",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#deriving-and-checking-gradient-formulas",
    "href": "chapters/03-maximum-likelihood.html#deriving-and-checking-gradient-formulas",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "Deriving and Checking Gradient Formulas",
    "text": "Deriving and Checking Gradient Formulas",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#a-complete-example-gradient-descent-for-laplace-regression",
    "href": "chapters/03-maximum-likelihood.html#a-complete-example-gradient-descent-for-laplace-regression",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "A Complete Example: Gradient Descent for Laplace Regression",
    "text": "A Complete Example: Gradient Descent for Laplace Regression",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  },
  {
    "objectID": "chapters/03-maximum-likelihood.html#solution",
    "href": "chapters/03-maximum-likelihood.html#solution",
    "title": "4  Maximum Likelihood Estimation and Gradients",
    "section": "Solution",
    "text": "Solution\nTo compute \\(\\frac{\\partial f}{\\partial x}\\), we treat \\(y\\) and \\(z\\) as constants, which yields\n\\[\n\\frac{\\partial f}{\\partial x} = 2x \\sin y + z^3\\;.\n\\]\nSimilarly, we can compute \\(\\frac{\\partial f}{\\partial y}\\) and \\(\\frac{\\partial f}{\\partial z}\\):\n\\[\n\\begin{align}\n    \\frac{\\partial f}{\\partial y} &= x^2 \\cos y + z \\\\\n    \\frac{\\partial f}{\\partial z} &= y + 3z^2 x\\;.    \n\\end{align}\n\\]",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maximum Likelihood Estimation and Gradients</span>"
    ]
  }
]